{
  "hash": "8731412c8fd3ed661f01aca4b81332f1",
  "result": {
    "markdown": "---\nexecute:\n  echo: false\n---\n\n::: {.cell}\n\n:::\n\n\n# Summary of changes from the 2017 pilot edition of the InCiSE Index {#sec-changes}\n\nThe 2019 edition of InCiSE incorporates a number of methodological\nchanges and improvement since the 2017 Pilot, which are the result of\ndesk research, stakeholder feedback and engagement since the pilot\npublication. This chapter provides a general  summary of the changes\nsince the 2017 Pilot.\n\n## Changes in the overarching methodology {#sec-changes-methodology}\n\nThere are two main changes to the overarching methodological approach\nfor the 2019 edition of InCiSE. Firstly, the technical modelling is\nbeing done in the R software package, rather than the mix of Excel and\nStata that was used for the pilot. This approach reduces the potential\nfor error, while the use of open source software will increase the\nopportunities for reproducibility. Secondly, a 'data quality assessment'\nhas been introduced which makes a quantitative appraisal of the data\nquality of countries and indicators. This assessment has been used to\ndetermine country selection, and to partially account for data quality in\nthe weighting of the indicators into the composite index score.\n\n\n## Indicators with no changes {#sec-no-change}\n\nThere are three indicators with no changes to their definition or\nmetrics â€“ policy making, inclusiveness and tax administration. For\npolicy making and tax administration there have been data updates to\nall metrics, while two of the five metrics in inclusiveness have been\nupdated.\n\n## Indicators with minor changes {#sec-minor-changes}\n\nThere are five indicators with what we class as 'minor' changes, that is\nchanges that we do not believe substantially change or which are not\ncontentious.\n\nFor the openness, integrity and regulation indicators we have identified some\nadditional metrics in the Bertelsmann Foundation's Sustainable Governance\nIndicators that enhance the topic coverage of these indicators.\n\nFor the integrity indicator we are also making a change to the coding of\npost-employment cooling-off periods to remove consideration of whether\ncompensation is paid during the cooling-off period due to quality concerns\nabout this aspect of the data.\n\nFor the fiscal & financial management indicator we are adding three metrics\n(one from the International Budget Partnership and two from the World Bank)\nthat measure government's openness/publication of budget and public spending\ndocuments and statistics.\n\nFor the HR management indicator we are incorporating newly published data from\nthe OECD on strategic HRM practices.\n\n## Crisis and risk management {#sec-change-crisis}\n\nThe crisis and risk management indicator has been redesigned, drawing from both\nthe 2017 Pilot source (the Hyogo Framework for Action monitoring reports) and\nnew data from the OECD on the governance of critical risks. The 2017 Pilot data\nfocuses heavily on natural disaster risk management, the OECD data\nsubstantially enhances the topic coverage and provide a more rounded view of\ncrisis and risk management practices.\n\n## Capabilities {#sec-change-capabilities}\n\nA data quality concern about the capabilities indicators is that the data for\nmost countries has a reference date of 2012. It has not been possible to\nidentify new and more up-to-date data for the capabilities indicator (the\nsource data is the OECD Survey of Adult Skills), although further datasets for\nthis data source that expand country coverage for this indicator were\nidentified. This led to a further review of the source data, which led to the\nidentification of a range of additional metrics that could be incorporated into\nthe model. The metrics in the pilot focused on capability levels (literacy,\nnumeracy, problem solving skills, and education level), however the data also\nincludes a number of metrics on the use of skills and learning at work (e.g.\nuse of reading/ writing/ IT skills at work, formal and informal learning for\njob-related reasons in the past 12 months). Furthermore, the pilot used data\nfor the public sector as a whole, however investigation of the source data\nsuggested that reliable estimates for the 'public administration' industrial\nsector could be produced (this is wider than just the civil service, including\nthings like local government, but excluding things such as healthcare,\neducation and transport). The capabilities indicator has therefore\nincorporated 10 additional metrics on skills use and learning at work, and\nswitched to using data for the 'public administration' industrial sector.\n\n## Digital services {#sec-change-digital}\n\nThe source data for digital services (the European Commission's eGovernment\nBenchmark Report) uses a 'life events' model, however for a number of these\nlife events delivery across the countries included in the dataset is at the\nsub-national/local level. Moreover, one of the domains (transparency) overlaps\nwith an existing InCiSE indicator. Therefore, the way in which data is\nextracted has been changed to select data for those life events where for a\nmajority of countries the service is delivered at the national level (and\ntherefore likely to be managed by the civil service) and to exclude the\ntransparency domain. \n\n## Procurement {#sec-change-procurement}\n\nSince the 2017 Pilot, two data sources have been identified that can provide\nmetrics for an indicator on procurement (an element of the InCiSE framework\nnot covered by the pilot). One source is the OECD's Survey on Public\nProcurement which looks at the role of CPBs and strategic approaches to public\nprocurement (e.g. e-procurement and support for SMEs). The other source is the\nOpentender project, supported by an academic consortium, which analyses the\ntender and contract notices for procurement exercises using the European\nUnion's Tenders Electronic Daily service. \n\n## Social security {#sec-change-social-security}\n\nThe 2017 Pilot included an indicator for social security. This was based on a\nsingle metric: administrative costs as a proportion of total social protection\nspending. Feedback received following the publication of the pilot identified\nsignificant quality issues with the metric used. No alternative metrics for\nthe indicator were identified, therefore it was decided to depreciate the\nindicator from the model. Further discussion of this is provided in\n@sec-future-development. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}