[
  {
    "objectID": "index.html#preface",
    "href": "index.html#preface",
    "title": "InCiSE 2019: Technical Report",
    "section": "Preface",
    "text": "Preface\nFrom 2016 to 2019, the International Civil Service Effectiveness (InCiSE) project was a collaboration between the Blavatnik School of Government and the Institute for Government. It was supported by the UK Civil Service (through the Cabinet Office) and funded by the Open Society Foundations.\nThe Blavatnik School of Government is re-establishing the InCiSE project with the aim of publishing a new edition of the InCiSE Index in 2024. To support engagement with stakeholders the School is re-publishing the 2019 project outputs (this Technical Report, the Results Report and interactive data visualisations) in more modern and user friendly formats.\nThis HTML version was made using Quarto.\n\nDifferences from the original 2019 publication\nPlease note, as part of the re-publication of this report into a web format Chapter 3 of the original report has had its constituent sections split into individual chapters to improve readability and navigation. Some typographic errors have been corrected as part of the re-publication of this report. There have also been some changes to the tables and figures when compared to the original report, these are largely for layout purposes (except in the case of one chart where external source data availability has changed). Footnotes have been added to charts, tables and chapters to indicate changes in content and differences in numbering.\nYou can also download and read the original PDF publication."
  },
  {
    "objectID": "index.html#preface-to-the-original-report",
    "href": "index.html#preface-to-the-original-report",
    "title": "InCiSE 2019: Technical Report",
    "section": "Preface to the original report",
    "text": "Preface to the original report\nTwo reports have been published covering the 2019 edition of the InCiSE Index:\n\nThe Results Report provides an overview of the overall results of the InCiSE Index, and a summary for each country covered by the Index.\nThe Technical Report (this report) provides the methodology of the InCiSE Index, it includes details fo the data sources, transformations, imputation, and weightings.\n\nUsers are free to copy, download and print InCiSE content and findings for their own use. Excerpts from InCiSE reports and publications may also be used, but must be appropriately referenced.\nThe Index is comprised of a variety of other data sources. Reuse is not applicable to data subject to intellectual property rights of third parties. Please refer to other organisations’ corresponding websites and data licensing restrictions to ensure compliance with their data limitations. Details of data sources can be found in the References section at the end of this report. Every effort has been made to adhere to third party data regulations.\n\nCitation\nPlease refer to and cite the original PDF publication:\n\nInCiSE Partners (2019) The International Civil Service Effectiveness (InCiSE) Index: Technical Report 2019, Oxford: Blavatnik School of Government, University of Oxford, https://www.bsg.ox.ac.uk/incise\n\n\n\nAcknoweldgements\nOur thanks go to those who have given their time to shape this second publication of the InCiSE Index. This has included substantial contributions made by academics, think-tanks and civil servants, past and present. Thanks also go to those organisations who have allowed us once again to use their data in the InCiSE Index, as well as their ideas and support for the overall project."
  },
  {
    "objectID": "00_contents.html#contents-of-the-report",
    "href": "00_contents.html#contents-of-the-report",
    "title": "Contents, figures and tables",
    "section": "Contents of the report",
    "text": "Contents of the report\nThis web book version of the report is structured into 17 chapters and two appendices.\n\n\nChapter 1: Introduction\n\nSection 1.1: Why InCiSE is needed\nSection 1.2: Defining the civil service\nSection 1.3: The InCiSE framework\nSection 1.4: The InCiSE data model\nSection 1.5: Eligibility of metrics\nSection 1.6: Technical approach\nSection 1.7: Quality considerations and limitations\nSection 1.8: Relationship with other indicators and data collections\nSection 1.9: Structure of this report\n\nChapter 2: Methodology of the InCiSE index\n\nSection 2.1: Data preparation\nSection 2.2: Data quality assessment\nSection 2.3: Country coverage selection\nSection 2.4: Imputation of missing data\nSection 2.5: Data normalisation\nSection 2.6: Calculation of the InCiSE indicators\nSection 2.7: Calculation of the InCiSE Index\nSection 2.8: Data quality considerations\nSection 2.9: Comparisons over time\n\nMethodology of the InCiSE indicators\n\nChapter 3: Integrity\n\nSection 3.1: Imputation of missing data\nSection 3.2: Changes from the 2017 pilot\n\nChapter 4: Openness\n\nSection 4.1: Imputation of missing data\nSection 4.2: Changes from the 2017 Pilot\n\nChapter 5: Capabilities\n\nSection 5.1: Imputation of missing data\nSection 5.2: Changes from the 2017 Pilot\n\nChapter 6: Inclusiveness\n\nSection 6.1: Imputation of missing data\nSection 6.2: Changes from the 2017 Pilot\n\nChapter 7: Policy making\n\nSection 7.1: Imputation of missing data\nSection 7.2: Changes from the 2017 Pilot\n\nChapter 8: Fiscal and financial management\n\nSection 8.1: Imputation of missing data\nSection 8.2: Changes from the 2017 Pilot\n\nChapter 9: Regulation\n\nSection 9.1: Imputation of missing data\nSection 9.2: Changes from the 2017 Pilot\n\nChapter 10: Crisis and risk management\n\nSection 10.1: Imputation of missing data\nSection 10.2: Changes from the 2017 Pilot\n\nChapter 11: Procurement\n\nSection 11.1: Imputation of missing data\nSection 11.2: Changes from the 2017 Pilot\n\nChapter 12: HR management\n\nSection 12.1: Imputation of missing data\nSection 12.2: Changes from the 2017 Pilot\n\nChapter 13: Tax administration\n\nSection 13.1: Imputation of missing data\nSection 13.2: Changes from the 2017 Pilot\n\nChapter 14: Digital services\n\nSection 14.1: Imputation of missing data\nSection 14.2: Changes from the 2017 Pilot\n\n\nChapter 15: Summary of changes from the 2017 pilot edition of the InCiSE Index\n\nSection 15.1: Changes in the overarching methodology\nSection 15.2: Indicators with no changes\nSection 15.3: Indicators with minor changes\nSection 15.4: Crisis and risk management\nSection 15.5: Capabilities\nSection 15.6: Digital services\nSection 15.7: Procurement\nSection 15.8: Social security administration\n\nChapter 16: Sensitivity analysis\n\nSection 16.1: Country selection\nSection 16.2: Reference date\nSection 16.3: Alternative approaches to weighting\nSection 16.4: Adjusting the base data\nSection 16.5: Alternative imputation methods\nSection 16.6: Results of the sensitivity analysis\n\nChapter 17: Future development\n\nSection 17.1: Social security administration\nSection 17.2: Functions and attributes not yet measured\nSection 17.3: Functions and attributes already measured\nSection 17.4: Extending country coverage\n\nReferences\n\nData sources\nSoftware packages\nPublished works and other materials\n\nAppendices\n\nAppendix A: Composite metrics\n\nSection A.1: Integrity\nSection A.2: Inclusiveness\nSection A.3: Fiscal and financial management\nSection A.4: Tax administration\nSection A.5: Procurement\nSection A.6: Crisis and risk management\n\nAppendix B: Sensitivity analysis – detailed results\n\n\n\n\n\n\n\n\nCross-referencing note\n\n\n\nChapters 3-14 of this web book were presented as a single chapter (Chapter 3) in the original 2019 publication. For improved navigation and readability this part of the report has been split into separate chapters. Footnotes have been added to charts, tables and chapters to indicate the resulting differences in numbering between this web book and the original PDF publication."
  },
  {
    "objectID": "00_contents.html#list-of-figures",
    "href": "00_contents.html#list-of-figures",
    "title": "Contents, figures and tables",
    "section": "List of figures",
    "text": "List of figures\n\n\nFigure 1.1: The InCiSE Index Framework\nFigure 1.2: The InCiSE data model\nFigure 5.1: Tertiary education levels of adults 25-34 and 55-64, in selected\nFigure 16.1: Sensitivity analysis results"
  },
  {
    "objectID": "00_contents.html#list-of-tables",
    "href": "00_contents.html#list-of-tables",
    "title": "Contents, figures and tables",
    "section": "List of tables",
    "text": "List of tables\n\n\nTable 1.1: Scope of the InCiSE Framework\n\n\n\nTable 2.1: Data quality assessment (DQA) results across the 12 InCiSE indicators and overall, for all 249 countries and territories considered by the InCiSE data model\nTable 2.2: Data quality assessment (DQA) results for the 38 countries included in the 2019 index\nTable 2.3: Data quality assessment (DQA) results by country\nTable 2.4: Data quality assessment (DQA) results by country for the next countries after the 38 selected for inclusion in the InCiSE 2019 model\nTable 2.5: InCiSE 2019 indicator weightings\nTable 2.6: Summary of data quality metadata for the 38 countries of the InCiSE 2019 Index\nTable 2.7: Overall quality assessment ‘RAG’ rating of the 2019 InCiSE indicators\nTable 2.8: Data quality scores by indicator and country\n\n\n\nTable 3.1: Composition of the integrity indicator\nTable 3.2: Coding of post-employment cooling-off in the 2017 Pilot edition of InCiSE\nTable 3.3: Coding of post-employment cooling-off in the 2019 edition of InCiSE\n\n\n\nTable 4.1: Composition of the openness indicator\n\n\n\nTable 5.1: Composition of the capabilities indicator countries\n\n\n\nTable 6.1: Composition of the inclusiveness indicator\n\n\n\nTable 7.1: Composition of the policy making indicator\n\n\n\nTable 8.1: Composition of the fiscal and financial management indicator\n\n\n\nTable 9.1: Composition of the regulation indicator\n\n\n\nTable 10.1: Composition of the crisis and risk management indicator\n\n\n\nTable 11.1: Composition of the procurement indicator\n\n\n\nTable 12.1: Composition of the HR management indicator\n\n\n\nTable 13.1: Composition of the tax administration indicator\n\n\n\nTable 14.1: Composition of the digital services indicator\nTable 14.2: Proportion of eGBR assessed services identified as ‘national’ level services\n\n\n\nTable 16.1: Reference year of InCiSE metrics by indicator\nTable 16.2: Variation in country ranking across sensitivity analyses\nTable 16.3: Summary of variation in ranking changes across sensitivity analysis sets\n\n\n\nTable 17.1: Potential future improvement of indicators measured in the 2019 edition of InCiSE\n\n\n\nTable A.1: Composite metrics in the integrity indicator\nTable A.2: Composite metrics in the inclusiveness indicator\nTable A.3: Composite metrics in the fiscal and financial management indicator\nTable A.4: Composite metrics in the tax administration indicator\nTable A.5: Composite metrics in the procurement indicator\nTable A.6: Composite metrics in the crisis and risk management indicator\n\n\n\nTable B.1: Sensitivity tests varying country coverage\nTable B.2: Sensitivity tests varying reference year\nTable B.3: Sensitivity tests with alternative approaches to weighting\nTable B.4: Sensitivity tests adjusting the base data\nTable B.5: Sensitivity tests adjusting the base data"
  },
  {
    "objectID": "00_readers_guide.html#country-codes",
    "href": "00_readers_guide.html#country-codes",
    "title": "Reader’s guide",
    "section": "Country codes",
    "text": "Country codes\nIn some tables and graphs countries are referred to by their three-letter ISO 3166-1 country codes, the codes for the 38 countries covered by the 2019 InCiSE Index are:\n\n\n\n\n\n\n\n\nCode\nCountry\n\n\n\n\nGBR\nUnited Kingdom\n\n\nNZL\nNew Zealand\n\n\nCAN\nCanada\n\n\nFIN\nFinland\n\n\nAUS\nAustralia\n\n\nDNK\nDenmark\n\n\nNOR\nNorway\n\n\nNLD\nNetherlands (the)\n\n\nKOR\nKorea (the Republic of)\n\n\nSWE\nSweden\n\n\nUSA\nUnited States of America (the)\n\n\nEST\nEstonia\n\n\nCHE\nSwitzerland\n\n\nIRL\nIreland\n\n\nFRA\nFrance\n\n\nAUT\nAustria\n\n\nESP\nSpain\n\n\nMEX\nMexico\n\n\nDEU\nGermany\n\n\nLTU\nLithuania\n\n\nBEL\nBelgium\n\n\nJPN\nJapan\n\n\nLVA\nLatvia\n\n\nCHL\nChile\n\n\nITA\nItaly\n\n\nSVN\nSlovenia\n\n\nISR\nIsrael\n\n\nPOL\nPoland\n\n\nPRT\nPortugal\n\n\nCZE\nCzechia\n\n\nISL\nIceland\n\n\nTUR\nTurkey\n\n\nSVK\nSlovakia\n\n\nBGR\nBulgaria\n\n\nHRV\nCroatia\n\n\nROU\nRomania\n\n\nGRC\nGreece\n\n\nHUN\nHungary"
  },
  {
    "objectID": "00_readers_guide.html#indicator-codes",
    "href": "00_readers_guide.html#indicator-codes",
    "title": "Reader’s guide",
    "section": "Indicator codes",
    "text": "Indicator codes\nThe following acronyms are used in some tables to refer to the 12 indicators measured in the InCiSE 2019 Index.\n\n\n\n\n\n\n\n\nCode\nIndicator\n\n\n\n\nCAP\nCapabilities\n\n\nCRM\nCrisis and risk management\n\n\nDIG\nDigital services\n\n\nFFM\nFiscal and financial management\n\n\nHRM\nHR management\n\n\nINC\nInclusiveness\n\n\nINT\nIntegrity\n\n\nOPN\nOpenness\n\n\nPOL\nPolicy making\n\n\nPRO\nProcurement\n\n\nREG\nRegulation\n\n\nTAX\nTax administration"
  },
  {
    "objectID": "01_introduction.html#sec-why-needed",
    "href": "01_introduction.html#sec-why-needed",
    "title": "1  Introduction",
    "section": "1.1 Why InCiSE is needed",
    "text": "1.1 Why InCiSE is needed\nAn effective civil service can play a vital role in determining a country’s progress and prosperity. But what constitutes an “effective civil service”? The functions of the central government are not always directly comparable to other organisations in a given country. Thus, international comparisons of government and civil service activity are often sought.\nInCiSE aims to define “effectiveness” more extensively than previous literature, drawing on a wide range of existing international data sources to bring together a set of indicators, each measuring a different dimension of civil service effectiveness. These indicators are then used to produce a composite (overall) score. This creation of a new and concise set of civil service effectiveness indicators therefore serves as:\n\nAn accountability tool: allowing citizens, government officials, and politicians to establish clearly and concisely how well their civil service is performing.\nA performance improvement tool: enabling senior decision makers to see the countries which perform best in each area, and therefore learn from them.\n\nInCiSE has been developed following a literature review and in consultation with many experts, including academics from schools of government, think-tanks that monitor government effectiveness, international organisations, senior civil servants (past and present) and subject matter experts. InCiSE has also been the subject of an independent, international peer review process. The 2019 edition of InCiSE has also benefited from the feedback collected and provided since the publication of the 2017 Pilot."
  },
  {
    "objectID": "01_introduction.html#sec-define-civil-service",
    "href": "01_introduction.html#sec-define-civil-service",
    "title": "1  Introduction",
    "section": "1.2 Defining the civil service",
    "text": "1.2 Defining the civil service\nCivil service effectiveness is well recognised in academic, international and practitioner communities as a highly complex area for analysis. As well as data limitations and the need to take account of country context factors, analysts are also faced with differing views on the definitions of both “civil service” and “effectiveness”. The scope, responsibilities, and structure of the civil service vary across countries, creating the need to establish exactly what is being assessed, and how. In defining the civil service there are a number of possible approaches to take:\n\nFirst, a civil service can be defined by function: a narrow view of the civil service through this definition focuses on the central, “upstream” agencies which set policy direction and procedural regulation for “downstream” agencies. The broader view encompasses agencies responsible for service delivery.\nSecond, a civil service can be defined by national accounts: this perspective sees the civil service as made up of entities which are owned by the government, and whose financial reporting places them within the System of National Accounts (SNA) category of General Government.\nThird, a civil service can be defined by employment regimes: under this definition, civil service entities are limited to those which are required to hire most employees under the civil service law, and those using other legal employment regimes are excluded.\n\nHowever, conceptual and practical problems arise under each of these definitions. For example, staff commonly referred to as “civil servants” do not always have legally distinct employee contracts; the SNA definition is inconsistent with the views of many practitioners and researchers; and each alternative conception results in a large and unwieldy group of agencies.\nInCiSE therefore takes a fourth and alternative approach, defining the scope of ‘civil services’ by outlining and measuring performance on the core functions of civil services; the parts which can generally be classified as civil service in every country. This approach leads to a focus on (i) functions which deliver services or affect citizens directly and (ii) public management and policy functions carried out in the centre of government.\nThe unit of analysis of interest for the InCiSE Index is the civil service, rather than the public sector more generally. InCiSE also focuses on civil service at the central/federal level – the highest level of government in a country/state – rather than at the regional or local level. Even with these parameters, isolating civil service performance with currently available data is still difficult, particularly given the varying sizes and shapes of civil services internationally.\nTable 1.1 gives more detail about what is included and excluded in the InCiSE Index.\n\n\n\n\nTable 1.1: Scope of the InCiSE Framework\n\n\nPart/function of the public sector\nDegree of inclusion in the InCiSE framework\n\n\n\n\nCivil service functions that deliver services to citizens and organisations directly (e.g. tax and social security administration at the central/ federal level).\nA primary focus of the InCiSE framework\n\n\nPublic administration functions of central government (e.g. fiscal management, policy making, regulation)\nA primary focus of the InCiSE framework\n\n\n'Mission support' functions (e.g. HRM and procurement) that support the operation of central government organisations.\nA primary focus of the InCiSE framework\n\n\nParts of the civil service which direct and support the wider public sector on specific policy areas (e.g. ministries of health or education) but may not deliver services to citizens directly.\nPerformance captured through the assessment of central government's public administration functions (e.g. policy making, regulation). Performance of policy areas themselves (e.g. quality of healthcare, educational attainment) are not assessed as these are not always the responsibility of central/federal government, moreover the policy goals and policy approaches taken are determined by political decision making.\n\n\nSub-national government/public administration (e.g. regional or local government)\nWhile in some jurisdictions employees of sub-national governments may be classed as civil servants (e.g. via employment law) the scope of InCiSE is principally with the central/federal level of government in a country/state. However, general government/public administration (incorporating both central and sub-national government) may be used as a proxy where no central-level civil service data is available.\n\n\nThe wider public sector (e.g. schools, hospitals, police forces).\nOut of scope. However, public sector data may be used as a proxy where no central-level civil service data is available.\n\n\n\nTable 1.2.A in the original PDF publication"
  },
  {
    "objectID": "01_introduction.html#sec-incise-framework",
    "href": "01_introduction.html#sec-incise-framework",
    "title": "1  Introduction",
    "section": "1.3 The InCiSE framework",
    "text": "1.3 The InCiSE framework\nThe purpose of the InCiSE framework is to define a common approach for assessing the effectiveness of a civil service, in a way which could realistically enable international data to be collected to measure against it. Whilst there are many alternative ways to define civil service effectiveness, the framework outlined here is informed by evidence and set out in such a way that if a civil service scores highly against it, it is reasonable to conclude that this civil service is high-performing relative to its international counterparts.\nOur approach to deriving a common framework was to:\n\nSpecify and adhere to a set of principles to inform the development of the framework:\n\nCoherent – identifying the key elements and drivers of effective public administration\nComprehensive – covering all relevant aspects and drivers of the performance of public administration\nActionable – offering genuine insights into what drives excellent public administration that can be implemented\nTransparent – a clear methodology and assessment process to ensure credibility, robustness, and replicability\nFeasible – it is possible to collect data for a large group of countries at reasonable cost\n\nDraw on evidence to identify key features of a draft framework which was then extensively tested through consultation.\nBuild on existing indicators and data where possible, striving to develop a more comprehensive framework capturing all aspects of civil service effectiveness.\nRefine the framework through consultation with a number of experts, including academics, think-tanks, international organisations, civil servants (both past and present) and subject experts.\n\nA common approach for assessing organisational effectiveness is to think in terms of inputs, outputs, and outcomes. However, this is appears less attractive when considering civil services and the public administration-type functions they provide. While output and outcome measures may have the advantage of cutting through conceptual uncertainty, they can be problematic in this area for three reasons:\n\nOutputs and outcomes can be affected by external factors, making it difficult to isolate the contribution of the civil service.\nMeasuring outputs and their value can be methodologically problematic, particularly as many public sector outputs are provided free at the point of consumption.\nFocusing on outputs and outcomes means that normative and procedural concerns which are also relevant to effectiveness can be ignored.\n\nGiven these concerns, the preferred approach here is to focus on the effectiveness of the procedures within the civil service which (often indirectly) affect outcomes. The framework’s approach is therefore more process focused and output focused, as outlined in Figure 1.1. An advantage of choosing process-based indicators is that they are more instructive for potential performance improvements – it is processes that are ultimately changed to increase effectiveness.\nAlthough procedural definitions also come with problems (they may not actually correlate with positive outcomes, for example) certain procedural measures remain at the core of any measure of effectiveness. Where there is evidence to support the relationship between procedures and positive outcomes, procedures may also be intrinsically beneficial. For example, meritocracy of recruitment procedures in the civil service are important because there is broad agreement that such procedures and outcomes are associated with an effective civil service. However, the extent to which recruitment processes reward merit is also important in the principle of fairness which is valued in itself.\n\n\nFigure 1.1: The InCiSE Index Framework\n\n\n\nThe InCiSE framework, shown in Figure 1.1, defines the core characteristics of an effective civil service. To do this, it assesses effectiveness on the basis of two interrelated dimensions: 1) the delivery of its core functions and 2) an underlying set of attributes which are important drivers of effectiveness across all parts of the civil service. Collectively the functions and attributes are called ‘indicators’ within the InCiSE model. Section 1.6 describes in more detail how the framework is implemented as a statistical model.\nFunctions: On one side, civil services deliver a set of central executive functions for ministers. These may help to formulate policy for the country (the effects of which are borne by citizens). On the other side, the services interact more directly with citizens through the delivery of services such as tax administration. Finally, in the centre, supporting these core external functions, are mission support functions such as HR management or IT services for officials. By looking across all three types of function, the aim is to measure how well civil services deliver the core elements of their roles. The functions identified by the InCiSE model are:\n\nPolicy making: The quality of the policy making process, including how policy is developed and coordinated across government and monitored during implementation.\nFiscal and financial management: The quality of the budgeting process and the extent to which spending decisions are informed through economic appraisal and evaluation.\nRegulation: The extent and quality of regulatory impact assessments and the degree of stakeholder engagement involved in them.\nCrisis and risk management: The effectiveness with which the government engages the whole of society to better assess, prevent, respond to and recover from the effects of extreme events.\nProcurement: The extent to which the procurement process is efficient, competitive, fair, and pursues value for money.\nHR management: The meritocracy of recruitment and the extent to which civil servants are effectively attracted, managed and developed.\nIT for officials: The extent to which civil servants have the technology and digital tools to work efficiently.\nInternal finance: The extent to which civil service operations are supported by well-managed and efficient finance systems, particularly on the alignment of finance with the business strategy and the level of civil servant satisfaction with finance support.\nTax administration: The efficiency and effectiveness of tax collection (at the central/federal level). Social security administration: The efficiency and effectiveness of social security administration (at the central/federal level).\nDigital services: The availability and usability of national-level digital public services.\n\nAttributes: Every civil service also has an underlying set of attributes which are important drivers of how effectively they deliver core functions. These attributes should apply to all parts of the civil service and are not specific to particular parts or functions. The inclusion of attributes in the framework is based on both a normative and a positive judgement: civil services should aim to cultivate and demonstrate these attributes as they are commonly (but not necessarily universally) understood as aspects of best practice, and the included attributes should generally be determinants of performance across all functions.\n\nIntegrity: The extent to which civil servants behave with integrity, make decisions impartially and fairly, and strive to serve both citizens and ministers.\nOpenness: The regular practice and degree of consultation with citizens to help guide the decisions we make and extent of transparency in our decision-making.\nCapabilities: The extent to which the workforce has the right mix of skills.\nInclusiveness: The extent to which the civil service is representative of the citizens it serves.\nStaff engagement: Staff levels of pride, attachment and motivation to work for their organisation.\nInnovation: The degree to which new ideas, policies, and ways of operating are able to freely develop.\n\nThe 2019 edition of InCiSE measures 12 of the 17 functions and attributes defined by the framework. Chapters 3-14 provides further detail of the definition and measurement of each of these indicators. Four of the five indicators (IT for officials, internal finance, staff engagement, and innovation) are not included because it has not been possible to identify suitable or sufficient data for cross-country measurement. One of the five indicators (social security administration) was measured in the 2017 Pilot but has been depreciated due to data quality concerns."
  },
  {
    "objectID": "01_introduction.html#sec-incise-datamodel",
    "href": "01_introduction.html#sec-incise-datamodel",
    "title": "1  Introduction",
    "section": "1.4 The InCiSE data model",
    "text": "1.4 The InCiSE data model\nThe InCiSE Index is based on a framework that describes the various components of an effective civil service. The Index operationalises this framework by measuring a series of indicators that correspond to the different components of the InCiSE framework. The overall InCiSE Index results are a composite of the indicator scores. In turn the indicators are split into themes, which describe important sub-divisions of the indicator. Scores for these themes are not computed but the theme structure is part of the weighting used in the calculation of the indicator scores. The themes within an indicator are represented by individual metrics, which ideally measure tangible qualities of the civil service that can be acted upon or influenced by senior officials. Most of the InCiSE metrics are single data points published by the data source providers, however some metrics are calculated from multiple data points. Figure 1.2 outlines the “data model” used by InCiSE, showing how individual data points from the external data sources combine to form the metrics, indicators and composite index of InCiSE.\nInCiSE is not intended to measure inputs (e.g. money/resources) or public policy outputs (e.g. unemployment benefits paid; taxes collected) or citizen outcomes (e.g. life expectancy, GDP per capita, citizen wellbeing), as these are typically determined by political decisions about the size of the state and what it is aiming to achieve. Rather, InCiSE is designed to assess the effectiveness of the way in which the civil service of a country uses the inputs it has been given to deliver the policy outputs/ outcomes that it has been set.\nOne of the main aims of the Index is to provide a mechanism for civil services to learn from each other: in particular to offer a data-driven approach to identify sources of good practice. To achieve this, InCiSE does not assess the absolute performance of different civil services. Instead, it converts the absolute performance captured in the individual metrics into relative assessments of performance of the countries included in the Index. This means that scoring poorly in InCiSE does not in itself indicate absolute poor performance, rather that when compared to other countries performance is lower. Similarly, scoring well in InCiSE does not in itself indicate absolute high performance, but that when compared to other countries performance is higher. The fact that there is no natural scale for civil service performance strengthens the case for measuring relative rather than absolute performance.\n\n\nFigure 1.2: The InCiSE data model"
  },
  {
    "objectID": "01_introduction.html#sec-metric-eligibility",
    "href": "01_introduction.html#sec-metric-eligibility",
    "title": "1  Introduction",
    "section": "1.5 Eligibility of metrics",
    "text": "1.5 Eligibility of metrics\nMetrics are eligible for inclusion in InCiSE if they meet the following criteria:\n\nThe data must be published in a free to-access form in the public domain and online. That is, an independent person must be able to access the data from a publicly accessible and free-to-use website.\nThe data must be actionable. That is, the data must measure some quality or component of the civil service that government officials and ministers can act on to improve performance. Where data for the civil service is not available, public sector proxies can be used, but these must still be data that represent something that can be acted on.\nThe data must be quantifiable, and if not directly collected and published as numerical data there must be a way to convert the data into a clear and relevant numerical format."
  },
  {
    "objectID": "01_introduction.html#sec-technical-approach",
    "href": "01_introduction.html#sec-technical-approach",
    "title": "1  Introduction",
    "section": "1.6 Technical approach",
    "text": "1.6 Technical approach\nThe technical approach for the 2019 model has used the 2017 InCiSE pilot edition of the model as the reference point for its methodology however the data collection and statistical model was rebuilt from first principles to provide a “clean slate” for the 2019 modelling. That is the 2019 model did not start as a copy of the 2017 final model with data updated to reflect the latest values with new data inserted and code amended. Instead, the 2019 model has been developed from scratch using R (rather than the mix of Excel and Stata used for the 2017 Pilot). This approach has been taken to (i) minimise the potential of error and improve quality assurance processes, and (ii) improve the openness, reproducibility and extensibility of the InCiSE model. The approach adopted for the 2019 InCiSE model is based on the Reproducible Analytical Pipelines approach developed by data scientists at the UK Government Digital Service (Gregory & Upson, 2017). The technical approach to coding and data management/processing was also influenced by the “tidyverse” principles Wickham (2015). A full list of the software packages used to develop and implement the modelling are listed in the References section at the end of this report."
  },
  {
    "objectID": "01_introduction.html#sec-quality-limitations",
    "href": "01_introduction.html#sec-quality-limitations",
    "title": "1  Introduction",
    "section": "1.7 Quality considerations and limitations",
    "text": "1.7 Quality considerations and limitations\nAs with any analytical endeavour, there are limitations to how far and in what ways the InCiSE Index can and can’t be used. Furthermore, given its early stage of development, the InCiSE Partners are clear that the index remains an experimental methodology that is subject to change and evolve in order to refine and improve the Index.\nThis section outlines some of the key considerations that should be taken into account when reviewing and using the InCiSE Index. Stating these limitations is not to downplay the value of the index as a tool for cross-country comparison, rather it is to help users understand the data they are using. Furthermore, InCiSE is not intended to be used in isolation but to enhance the range of evidence available about government effectiveness. Users should build a “rich picture” of the situation by triangulation across the results from InCiSE, the underlying results from InCiSE’s source metrics or other international comparisons, and domestic information for which there is no international comparisons.\nThere are a number of different aspects that should be taken into consideration in regards to the quality of data used in InCiSE:\n\nRecency and frequency of the data: InCiSE 2019 uses the most recently available data as at 30 November 2018. Some metrics in InCiSE are collected annually, others biennial or longer, or are ad-hoc in their repetition. As a result, some metrics may use data that does not accurately reflect the most recent situation.\nDepth of the data: Some metrics represent a single measure in a survey, some are aggregations of multiple measures by the InCiSE model, while some are composite indicators compiled by others parties that are based on a range of metrics.\n“Spill over”: Some measures that contribute to one of the InCiSE indicators may be relevant to other indicators, but wherever possible this has been avoided. No original piece of data used by the InCiSE model is used more than once in order to ensure that the overall figures are not overly-reliant on a particular data source.\nPublic sector proxy: The purpose of the InCiSE Index is to measure the effectiveness of a country’s national and central civil service. However, some metrics measure the performance of the public sector at large – or at least a larger subset than the specific unit of analysis that InCiSE is interested in. In this case the public sector measures can only be considered proxies.\nProxy measures of effectiveness: The true nature of the effectiveness of a country’s civil service is inherently unobservable, and cannot be comprehensively observed in an empirical study. The purpose of the InCiSE project is to provide a means to combine a range of proxy measures to provide insight into the effectiveness of civil services. The InCiSE framework enables this analysis by providing a way to conceptualise how a civil service operates. The model therefore uses measures about the functions and attributes of a civil service to produce an estimate of effectiveness."
  },
  {
    "objectID": "01_introduction.html#sec-relationship",
    "href": "01_introduction.html#sec-relationship",
    "title": "1  Introduction",
    "section": "1.8 Relationship with other indicators and data collections",
    "text": "1.8 Relationship with other indicators and data collections\nIn setting the civil service as our unit of interest, it is also important to distinguish the difference of InCiSE with other ‘governance’ indicators (particularly the World Bank’s Worldwide Governance Indicators and the Bertelsmann Foundation’s Sustainable Governance Indicators). Other governance indicators take a broad view of the topic of governance, including assessments of political decision making within governing parties, the quality of democracy, the ability to hold the government to account, and the freedoms of media and civil society. These are important factors in considering the governance of a country in general. InCiSE seeks to complement these ‘broad’ assessments of governance by providing a deeper investigation with a narrower focus on a key element of the operation of government – the civil service.\nBesides ‘broad’ governance indicators there are also thematic indicators that focus on specific elements of governance; for example, the World Wide Web Foundation’s Open Data Barometer, the World Justice Project’s Rule of Law Index or the OECD’s regulation indicators. There are also indicators focused on other themes that cut across sectoral boundaries (for example Transparency International’s Global Corruption Barometer, or the World Economic Forum’s Doing Business Report) which contain a large amount of information about countries but where only a few measures directly relate to central government/civil service performance.\nFinally, there are also a range of data collections made by international organisations and other institutions (notably the OECD, the European Commission, and the United Nations) about the functioning of government/the civil service but which do not produce single composite assessments.\nThe InCiSE framework and index has been designed and developed to re-use data from these indicators and data sources to produce a single coherent and comparable data model that allows a wide variety of parties interested in civil service reform to make a high-level assessment of how the civil services of different countries compare. The InCiSE Index should not be used in isolation, but in combination with reference to the source datasets as well as with domestic data from within a country about performance across the various indicators.\nFurther considerations about the specific data quality of the InCiSE data and results is provided in Chapters 3-14."
  },
  {
    "objectID": "01_introduction.html#sec-report-structure",
    "href": "01_introduction.html#sec-report-structure",
    "title": "1  Introduction",
    "section": "1.9 Structure of this report",
    "text": "1.9 Structure of this report\nThis Technical Report on the InCiSE Index is intended to describe the methodology, data and limitations of the approach used. The results of the Index can be found in the accompanying 2019 Results Report. Including the introductory chapter, there are seven chapters in this report:\n\nChapter 2: Methodology of the InCiSE Index outlines the data processing, calculation of the InCiSE indicators, and calculation of the InCiSE Index.\nChapter 3: Methodology of the InCiSE indicators sets out the methodology for each of the 12 indicators that make up the 2019 index.\nChapter 4: Summary of changes from the 2017 Pilot highlights the changes made within the methodology of each indicator, as well as in the overarching methodology of the index.\nChapter 5: Sensitivity analysis describes some of the uncertainties associated with the modelling process and subjective choices, and the consequent impact on the Index results.\nChapter 6: Future development sets out the next steps for future consideration and development of the index methodology.\n\nThere are also two annexes to the report that provide additional detail:\n\nAnnex A: Composite metrics provides details of how the different composite metrics used in the InCiSE Index have been constructed.\nAnnex B: Sensitivity analysis results provides detailed results of the different tests conducted as part of the sensitivity analysis.\n\n\n\n\n\nGregory, M. & Upson, M. (2017). RAP Companion: Automating the production of statistical reports using DataOps principles. London, UK: UK Government Digital Service. Retrieved from https://ukgovdatascience.github.io/rap_companion/\n\n\nWickham, H. (2015). R Packages. Sebastopol, CA: O’Reilly. Retrieved from https://r-pkgs.had.co.nz\n\n\nWickham, H. & Grolemund, G. (2017). R for data science. Sebastapol, CA: O’Reilly. Retrieved from https://r4ds.had.co.nz"
  },
  {
    "objectID": "02_index.html#sec-data-prep",
    "href": "02_index.html#sec-data-prep",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.1 Data preparation",
    "text": "2.1 Data preparation\nThe data for InCiSE comes from a wide range of independent sources, such as the UN’s E-Government Survey, Transparency International’s Global Corruption Barometer, and Bertelsmann’s Sustainable Governance Indicators (SGIs).1 The InCiSE partnership does not produce any of the source data itself or engage in primary data collection.1 A full list of data sources can be found in the References section at the end of this report.\nThe data for the 2019 edition of InCiSE is the latest available as of 30 November 2018. As well as the source metrics some additional data are collected to aid in the imputation of missing data – this data does not directly contribute to the scores and therefore is not included in the published results.\nSome of the source data requires processing before it is suitable for use in the InCiSE calculations and modelling. For example:\n\nBinary/multiple categorical data: some of the source data are binary measures (e.g. yes/no questions) or assess multiple categories (e.g. groups subject to whistleblower protection). In most cases this type of data is summed.\nIndividual level microdata: InCiSE uses a custom analysis of the Programme for the International Assessment of Adult Competencies (PIAAC) individual-level microdata to produce country scores. The Opentender data on procurement is on individual contracts, which also requires analysis to produce country scores.\nNegatively framed data: Some of the source data is based on negatively framed questions, where a higher score is poorer performance than a lower score. To align with other metrics, this data is inverted so that higher scores relate to better performance than lower scores.\nCalculations against reference data: For the inclusiveness indicator, women’s representation in the civil service/public sector is compared to the labour market in general. Tax administration from the OECD is published as raw data. InCiSE uses rates based on these data which must therefore be calculated.\n\nChapters 3-14 outline the underlying source data for each of the indicators, and covers the specific transformations that are applied to the source data. Appendix A outlines the construction and calculation of the composite metrics (metrics calculated from more than a single data point in the original source) that are included in some of the indicators.\nWhen importing data to the InCiSE model, data is matched against a reference list of 249 countries and territories produced by Arel-Bundock et al. (2018) using the 3-digit ISO 3166-1 alphanumeric codes. Some source data natively uses the 3-digit ISO country codes, but some use the 2-digit ISO code, another code system, or a name of the territory (either the official long/short name, or colloquial name). Therefore, as part of data preparation, all country references are converted to the 3-digit ISO country code."
  },
  {
    "objectID": "02_index.html#sec-data-quality",
    "href": "02_index.html#sec-data-quality",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.2 Data quality assessment",
    "text": "2.2 Data quality assessment\nIn order to provide a clearer understanding of the quality of the InCiSE Index, a data quality assessment has been calculated and published alongside the 2019 edition. This assessment has a dual role: it is an important piece of metadata that will help users of the InCiSE Index better understand the results, but it has also been used to determine the country coverage of the InCiSE Index. This section describes the method for conducting the data quality assessment. The use of the assessment for country selection and weighting are discussed in sections Section 2.3 and Section 2.7 respectively, while a wider discussion of data quality based on the results of the assessment is provided at section Section 2.8.\nThe data quality assessment is a purely quantitative exercise based on three factors: data availability, the (non-)use of public sector proxy data, and the recency of the data. The assessment does not include any subjective evaluation of the methodology or the quality of the data sources that the underlying data used by InCiSE comes from.\nThe data quality assessment also does not incorporate assessments of the reliability or validity of indicator and index construction. Its purpose is to provide an assessment of easily quantifiable characteristics of the data, which can help interpretation of the InCiSE results for countries and of the indicators.\nThe simple mean of the three measures is taken as the data quality score for each country for each indicator. The 12 overall indicator quality scores are then combined as a simple mean score to produce an overall data quality assessment for each country.\nFor each indicator, the data quality assessment is based on three measures: (1) the proportion of metrics with data; (2) the proportion of metrics that have civil service specific data; and (3) the recency of the data. All three measures take a simple assessment of whether data is missing or present as their basis. However, each measure has different weighting rules for the data:\n\nData availability: A missing data point fora metric with a within-indicator weight of 15% will give a greater penalty than a missing data point for a metric with a within-indicator weight of 5%.\nCivil service data (1) or a public sector proxy (0): Data points that come from public sector data are treated as equivalent to being missing.\nRecency of the data: The reference year of the metric is scaled from 0 (for 2012, the earliest year) to 1 (for 2018, the latest year) and used as the weighting.2\n\n2 For example a datapoint with a reference year of 2013 will be weighted 0.1667, while one with a reference year of 2016 will be weighted 0.6667.The country indicator data quality scores and overall data quality assessment (\\(DQA_{c,i}\\)) for a given country (\\(c\\)) and indicator (\\(i\\)) is calculated by multiplying the missing data matrix of the metrics in the indicator for that country (\\(d_{c,i}\\)) by each of: the within indicator weighting for the metrics in the indicator (\\(m_i\\)), the proxy data status of each metric in the indicator (\\(s_i\\)), and the recency of each metric in the indicator (\\(r_i\\)). The resulting products are summed and divided by three to give the mean data quality for that country and indicator.\n\\[\nDQA_{c,i} = \\frac{{(d_{c,i} * m_i) + (d_{c,i} * s_i) + (d_{c,i} * r_i)}}{3}\n\\]\nThe overall data quality indicator for a country (\\(DQA_c\\)) is then calculated as the sum of data quality assessment scores of that country for each indicator divided by the number of indicators (\\(n_i\\)).\n\\[\nDQA_c = \\frac{\\sum{DQA_{c,i}}}{n_i}\n\\]\nThe data quality assessment scores therefore have a theoretical range from 0 to 1. Where 0 represents there being no metrics available and 1 represents there being data for all metrics, with all data representing the civil service (i.e. not using a public-sector proxy) and all data relating to the latest available year. Table 2.1 illustrates the complex picture of data quality across all countries and indicators.\nThe table shows how maximum data quality varies from 0.333 for capabilities, where the available data is for a public sector proxy and the oldest data in the model, to 1.000 for policy making, where all the available data relates to the civil service and is at the latest available data.\nThe indicators for openness, fiscal & financial management and crisis & risk management have good data quality (DQA score greater than or equal to 0.5) for a very large number of countries. Other indicators (such as HR management or tax administration) have a moderate number of countries with good data quality, but have a large number of countries with poorer data quality. Finally, some indicators (such as digital services or policy making) have data for only a small number of countries, which is typically due to the source data covering only OECD or EU members (or both).\n\n\n\n\nTable 2.1: Data quality assessment (DQA) results across the 12 InCiSE indicators and overall, for all 249 countries and territories considered by the InCiSE data model\n\n\nIndicator\nHighest country DQA score\nDistribution of country DQA scores\n\n\nDQA ≥ 0.5\n0.5 &gt; DQA &gt; 0\nDQA = 0\n\n\n\n\nCapabilities\n0.333\n0\n31\n218\n\n\nCrisis & risk management\n0.855\n95\n13\n141\n\n\nDigital services\n0.581\n34\n0\n215\n\n\nFiscal & financial management\n0.889\n109\n88\n52\n\n\nHR management\n0.673\n37\n83\n129\n\n\nInclusiveness\n0.722\n34\n82\n133\n\n\nIntegrity\n0.569\n30\n127\n92\n\n\nOpenness\n0.928\n105\n93\n51\n\n\nPolicy making\n1.000\n41\n0\n208\n\n\nProcurement\n0.722\n20\n24\n205\n\n\nRegulation\n0.963\n38\n5\n206\n\n\nTax administration\n0.852\n46\n141\n62\n\n\nOverall data quality assessment\n0.757\n38\n162\n49\n\n\n\nTable 2.2.A in the original PDF publication"
  },
  {
    "objectID": "02_index.html#sec-coverage",
    "href": "02_index.html#sec-coverage",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.3 Country coverage selection",
    "text": "2.3 Country coverage selection\nFor the 2017 Pilot edition of the InCiSE Index only two countries had data for all 76 metrics, and a simple threshold of 75% data availability plus membership of the OECD were used as the selection criteria for country availability. However, analysis of the pilot showed (as Table 2.1 shows) that there is a mixed picture of data availability and quality across indicators which is not reflected in this simple threshold. The data quality assessment outlined in Section 2.2 provides a more nuanced way to consider the variation of data availability and quality, and is therefore used to determine which countries are included in the final version of the index for the InCiSE 2019.\nIn determining country coverage, the InCiSE Partners have decided to use an overall data quality assessment score of 0.5 or greater for the threshold for country inclusion. 38 countries reached this score. Although two further countries would be included if data quality scores were rounded to 1 decimal place, these two countries have lower data availability (57% and 51% of all metrics respectively), which is judged to be too low for reliable analysis. Therefore, the 38 countries with a data quality score of 0.5 or higher (when rounded to 2-decimal places) are included in the 2019 edition of the InCiSE Index. This includes all 31 countries covered by the InCiSE pilot.\nTable 2.2 provides an overview of the country-level data quality scores for the group of 38 countries. The table shows that for most indicators the 38 countries have generally good data quality. However, for four indicators (capabilities, crisis & risk management, digital services and procurement) there are a small number of countries with no available data at all.\nTable 2.3 provides a summary of the data quality assessment for all 38 countries selected for the 2019 edition of InCiSE, Table 2.4 provides the assessment for the five countries with the next highest data quality score. One country (the United Kingdom) achieved the highest overall data quality score of 0.757, followed closely by five others (Italy, Poland, Sweden, Norway and Slovenia). Countries included for the first time in the 2019 edition of the Index are flagged with the “[new]” marker next to their country name in Table 2.3.\nFurther discussion on data quality issues are provided at the end of this chapter in section Section 2.8, covering both the quality of the indicators and interpretation of country level results from the InCiSE Index.\n\n\n\n\nTable 2.2: Data quality assessment (DQA) results for the 38 countries included in the 2019 index\n\n\nIndicator\nLowest country DQA score\nHighest country DQA score\nMean country DQA score\nDistribution of country DQA scores\n\n\nDQA ≥ 0.5\n0.5 &gt; DQA &gt; 0\nDQA = 0\n\n\n\n\nCapabilities\n0.000\n0.333\n0.244\n0\n38\n10\n\n\nCrisis & risk management\n0.000\n0.855\n0.631\n26\n12\n1\n\n\nDigital services\n0.000\n0.581\n0.444\n29\n9\n9\n\n\nFiscal & financial management\n0.439\n0.889\n0.783\n37\n1\n0\n\n\nHR management\n0.293\n0.673\n0.640\n35\n3\n0\n\n\nInclusiveness\n0.375\n0.722\n0.663\n33\n5\n0\n\n\nIntegrity\n0.402\n0.569\n0.526\n29\n9\n0\n\n\nOpenness\n0.283\n0.928\n0.818\n35\n3\n0\n\n\nPolicy making\n1.000\n1.000\n1.000\n38\n0\n0\n\n\nProcurement\n0.000\n0.722\n0.513\n20\n18\n2\n\n\nRegulation\n0.339\n0.963\n0.908\n35\n3\n0\n\n\nTax administration\n0.352\n0.852\n0.770\n34\n4\n0\n\n\nOverall data quality\n0.501\n0.757\n0.662\n38\n0\n0\n\n\n\nTable 2.3.A in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n\nTable 2.3: Data quality assessment (DQA) results by country\n\n\nCode\nCountry\nOverall DQA score\nPercent of metrics available\nNumber of indicators where: 0.5 &gt; DQA &gt; 0\nIndicators with completely missing data (DQA = 0)\n\n\nNumber\nIndicators\n\n\n\n\nGBR\nUnited Kingdom\n0.757\n100%\n1\n0\n\n\n\nITA\nItaly\n0.755\n99%\n1\n0\n\n\n\nPOL\nPoland\n0.755\n99%\n1\n0\n\n\n\nSWE\nSweden\n0.755\n99%\n1\n0\n\n\n\nNOR\nNorway\n0.752\n99%\n1\n0\n\n\n\nSVN\nSlovenia\n0.750\n99%\n1\n0\n\n\n\nAUT\nAustria\n0.738\n98%\n1\n0\n\n\n\nFIN\nFinland\n0.736\n97%\n2\n0\n\n\n\nESP\nSpain\n0.733\n97%\n1\n0\n\n\n\nNLD\nThe Netherlands\n0.731\n98%\n1\n0\n\n\n\nFRA\nFrance\n0.718\n97%\n2\n0\n\n\n\nPRT\nPortugal\n0.716\n85%\n1\n1\nCAP\n\n\nDNK\nDenmark\n0.707\n93%\n2\n0\n\n\n\nDEU\nGermany\n0.701\n96%\n2\n0\n\n\n\nGRC\nGreece\n0.696\n94%\n2\n0\n\n\n\nSVK\nSlovakia\n0.692\n93%\n1\n0\n\n\n\nHUN\nHungary\n0.671\n81%\n1\n1\nCAP\n\n\nEST\nEstonia\n0.669\n90%\n2\n0\n\n\n\nCZE\nCzechia\n0.659\n91%\n3\n0\n\n\n\nTUR\nTurkey\n0.650\n90%\n4\n0\n\n\n\nMEX\nMexico\n0.648\n73%\n3\n2\nCAP, DIG\n\n\nNZL\nNew Zealand\n0.644\n83%\n4\n1\nDIG\n\n\nCHL\nChile\n0.643\n79%\n4\n1\nDIG\n\n\nCAN\nCanada\n0.638\n78%\n4\n1\nDIG\n\n\nKOR\nRepublic of Korea\n0.636\n78%\n4\n1\nDIG\n\n\nBEL\nBelgium\n0.635\n85%\n3\n1\nCRM\n\n\nLVA\nLatvia [new]\n0.628\n75%\n2\n1\nCAP\n\n\nCHE\nSwitzerland\n0.627\n79%\n2\n1\nCAP\n\n\nAUS\nAustralia\n0.618\n71%\n3\n3\nCAP, DIG, PRO\n\n\nLTU\nLithuania [new]\n0.615\n82%\n5\n0\n\n\n\nIRL\nIreland\n0.614\n84%\n4\n0\n\n\n\nJPN\nJapan\n0.597\n75%\n5\n1\nDIG\n\n\nUSA\nUnited States of America\n0.579\n74%\n4\n2\nDIG, PRO\n\n\nISR\nIsrael [new]\n0.578\n72%\n5\n1\nDIG\n\n\nISL\nIceland [new]\n0.563\n68%\n5\n1\nCAP\n\n\nROU\nRomania [new]\n0.529\n66%\n5\n1\nCAP\n\n\nBGR\nBulgaria [new]\n0.511\n66%\n6\n1\nCAP\n\n\nHRV\nCroatia [new]\n0.501\n65%\n6\n1\nCAP\n\n\nNA\nMean of 38 countries\n0.635\n82%\n3\n1\n\n\n\n\nTable 2.3.B in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n\nTable 2.4: Data quality assessment (DQA) results by country for the next countries after the 38 selected for inclusion in the InCiSE 2019 model\n\n\nCode\nCountry\nOverall DQA score\nPercent of metrics available\nNumber of indicators where: 0.5 &gt; DQA &gt; 0\nIndicators with completely missing data (DQA = 0)\n\n\nNumber\nIndicators\n\n\n\n\nCOL\nColumbia\n0.471\n57%\n6\n3\nCAP, DIG, POL\n\n\nLUX\nLuxembourg\n0.460\n51%\n7\n2\nCAP, INC\n\n\nCYP\nCyprus\n0.435\n64%\n9\n1\nCRM\n\n\nCRI\nCosta Rica\n0.417\n48%\n7\n3\nCAP, DIG, POL\n\n\nMLT\nMalta\n0.375\n49%\n9\n2\nCAP, CRM\n\n\n\nTable 2.3.B in the original PDF publication"
  },
  {
    "objectID": "02_index.html#sec-imputation",
    "href": "02_index.html#sec-imputation",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.4 Imputation of missing data",
    "text": "2.4 Imputation of missing data\nAs seen in Table Table 2.3 only one country has complete data (i.e. 100% of metrics). The average level of data availability is 86% across the 38 countries, and 7 of the included countries have data availability below the 75% threshold used for the 2017 Pilot, with the lowest level of data availability being 65%. Of the 38 countries, 15 have one indicator with a data quality score of 0 (i.e. no data at all for that indicator), two countries have two indicators with a data quality score of 0 and one country has three indicators with a data quality score of 0.\nThis presents issues for the analysis of the data and providing an effective method for aggregating the metrics into indicators and an overall index. The 2017 Pilot edition of InCiSE adopted two methods for imputation: multiple imputation using linear regression and median imputation. For the 2019 edition of InCiSE a decision has been made to move fully to a multiple imputation approach, using the ‘predictive mean matching’ (PMM) technique of van Buuren & Groothuis-Oudshoorn (2011). The PMM technique uses correlation – of both the values and pattern of missing data – to identify for a country with missing data those countries in the dataset that closely match it, and randomly select one of those to replace the missing value. Following the approach set out by van Buuren (2018), for each missing value 15 imputations are generated (each of which has also been iterated 15 times). A simple mean of these 15 imputation values is then calculated and used as the country’s value in the ‘final’ dataset.\nImputation is handled on a per-indicator basis – in most cases imputation will be solely from within the metrics of that indicator. However, a few indicators have external predictors, either data from elsewhere in the InCiSE model or from an external data source. Full details of the imputation approach for each indicator are described in Chapters 3-14."
  },
  {
    "objectID": "02_index.html#sec-normalisation",
    "href": "02_index.html#sec-normalisation",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.5 Data normalisation",
    "text": "2.5 Data normalisation\nAs a result of coming from different sources, the underlying data that drives the InCiSE model has a variety of formats: some are proportions or scores from 0 to 1 or 0 to 100; some are ratings on a scale, or the average of ratings given by a set of assessors/survey participants; and some are counts. The different formats of these data are not easily comparable, and cannot be directly averaged together to produce a combined score. In order to facilitate the comparison and combination of data from different sources, the metrics are normalised so that they are all in a common format.\nThere are a number of normalisation techniques that could be used. A useful discussion of the different methods is provided in the OECD et al. (2008) Handbook on Constructing Composite Indicators. The InCiSE Index uses min-max normalisation at all stages, as this maintains the underlying distribution of each metric while providing a common scale of 0 to 1. The common scale is of particular benefit, as it helps achieve InCiSE’s goal of assessing relative performance. In the min-max normalisation 0 represents the lowest achieved score and 1 represents the highest achieved score. It is therefore important to note that scoring 0 on a particular metric, indicator or the index itself does not represent poor performance in absolute terms, nor does scoring 1 represent high performance in absolute terms. Rather the country is either the lowest or highest performing of the 38 countries selected.\nThe min-max normalisation operates via the following mathematical formula:\n\\[\nm_c = \\frac{x_c-x_{min}}{x_{max}-x_{min}}\n\\]\nFor a metric for a given country its normalised score (\\(m_c\\)) is calculated as the difference of the country’s original score (\\(x_c\\)) from the metric’s minimum score (\\(x_min\\)) divided by the range of the metric’s scores (the difference of the metric’s maximum score (\\(x_max\\)) from the metric’s minimum score (\\(x_min\\))."
  },
  {
    "objectID": "02_index.html#sec-calc-indicators",
    "href": "02_index.html#sec-calc-indicators",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.6 Calculation of the InCiSE indicators",
    "text": "2.6 Calculation of the InCiSE indicators\nOnce the data has been processed, missing data imputed, and the metrics normalised, the InCiSE indicators can be calculated. There are two stages to the calculation of the indicators: the weighting of the metrics into an aggregate score, and the normalisation of that score.\nAs outlined in Figure 1.2, the InCiSE data model first groups metrics into themes before aggregating into the indicator scores themselves. These themes are purely structural and scores for them are not computed. The raw score for an indicator follows this formula:\n\\[\ni_c = \\sum{(m_{i,c}*w_m*w_t)}\n\\]\nA country’s raw score for an indicator (\\(i_c\\)) is calculated as the sum of the product of each metric within the indicator for that country (\\(m_{i,c}\\)) with the weight of that metric within its theme (\\(w_m\\)) and the weight of that theme within the indicator (\\(w_t\\)). The weighting structure for each indicator are listed in detail in Chapters 3-14. After the raw scores are calculated they are normalised as described in Section 2.5 above."
  },
  {
    "objectID": "02_index.html#sec-calc-index",
    "href": "02_index.html#sec-calc-index",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.7 Calculation of the InCiSE Index",
    "text": "2.7 Calculation of the InCiSE Index\nThe InCiSE Index is an aggregation of the InCiSE indicators. Ideally, the indicators would be combined equally, however in producing the 2017 Pilot edition the InCiSE Partners felt it important to consider relative data quality. In the 2017 Pilot this was done by placing a lower weight on the indicators measuring ‘attributes’ than those measuring’functions’, as the four attribute indicators were considered to generally have lower data quality than those measuring functions. The 2019 edition builds on this approach to weighting by using the results of the data quality assessment (section Section 2.2).\nFor this approach to weighting, two-thirds of the weighting is allocated on an equal basis, while one third is allocated according to the outcome of the data quality assessment. The weight for an indicator is calculated as follows:\n\\[\nw_i = \\left(\\frac{2}{3}*\\frac{1}{n_i}\\right) + \\left(\\frac{1}{3}*Q_i\\right)\n\\]\nHere the indicator weight (\\(w_i\\)) is equal to the product of two-thirds and the equal share (1 divided by \\(n_i\\), the number of indicators; i.e. 1/12) plus the product of one-third and the data quality weight for the indicator (\\(Q_i\\)). The data quality weight is calculated first by summing the data quality scores of the 38 selected countries for the indicator. The indicator’s data quality sum is then divided by the sum of all indicator data quality scores, in essence providing a score that represents that indicator’s share of the total data quality for the 38 countries selected. The resulting weights are shown in Table Table 2.5.\nA country’s overall raw index score (\\(I_c\\)) is thus calculated as the sum of the product of the normalised indicator scores for the country (\\(i_c\\)) with the indicator weights (\\(w_i\\)):\n\\[\nI_c = \\sum{(i_c * w_i)}\n\\]\nAfter calculating the raw index scores, they are then are normalised as outlined in Section 2.5, resulting in the overall index scores for the 2019 edition of InCiSE.\n\n\n\n\nTable 2.5: InCiSE 2019 indicator weightings\n\n\nInCiSE indicator\nSum of data quality scores\nShare of total data quality scores\nFinal weight\nApproximate fraction\n\n\n\n\nCapabilities\n9.271\n3.1%\n6.6%\n1/15\n\n\nCrisis & risk management\n23.967\n7.9%\n8.2%\n1/12\n\n\nDigital services\n16.855\n5.6%\n7.4%\n1/13\n\n\nFiscal and financial management\n29.763\n9.9%\n8.8%\n1/11\n\n\nHR management\n24.332\n8.1%\n8.2%\n1/12\n\n\nInclusiveness\n25.188\n8.3%\n8.3%\n1/12\n\n\nIntegrity\n19.995\n6.6%\n7.8%\n1/13\n\n\nOpenness\n31.100\n10.3%\n9.0%\n1/11\n\n\nPolicy making\n38.000\n12.6%\n9.8%\n1/10\n\n\nProcurement\n19.500\n6.5%\n7.7%\n1/13\n\n\nRegulation\n34.510\n11.4%\n9.4%\n1/11\n\n\nTax administration\n29.269\n9.7%\n8.8%\n1/11\n\n\nOverall\n301.749\n100.0%\n100.0%\n\n\n\n\nTable 2.7.A in the original PDF publication"
  },
  {
    "objectID": "02_index.html#sec-considerations",
    "href": "02_index.html#sec-considerations",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.8 Data quality considerations",
    "text": "2.8 Data quality considerations\nSections Section 2.3 and Section 2.7 illustrate how the data quality assessment described in section Section 2.2 is used within the InCiSE model for country selection and indicator weighting.\nThe assessment can also be used to help interpret the results of the InCiSE Index, both in terms of the quality of the indicators and for country results.\n\n2.8.1 Quality of indicators\nThe data quality assessment conducts three checks for each indicator: the availability of metrics, the (non-)use of wider public sector data as a proxy, and the recency of the data. Table 2.6 summarises the results of these three checks for each of the indicators.\nAs discussed in sections Section 2.3 and Section 2.4 there are four indicators where at least one country is missing all data for the indicator. Conversely, there is only one indicator (policy making) where all 38 countries have all data available. When it comes to the use of public sector proxy data, there are six indicators where all the data is not a public sector proxy, giving the indicators a maximum proxy data score of 1, and only two indicators (capabilities and digital services) where all the data relates to the civil service and is not public sector proxy which means their maximum proxy score is 0. The recency calculation is a relative assessment where the oldest data (2012) scored 0 and the most recent data (2018) scored 1 – here we see that only one indicator (policy making) is composed solely of 2018 data and again only one indicator (capabilities) is composed solely of 2012 data.\n\n\n\n\nTable 2.6: Summary of data quality metadata for the 38 countries of the InCiSE 2019 Index\n\n\nInCiSE indicator\nData availability\nPublic sector proxy\nRecency of data\nOverall DQA score\nCountries with max DAQ score\nMean DQA score\nRAG rating\n\n\nMin\nMax\nMin\nMax\nMin\nMax\nMin\nMax\n\n\n\n\nCapabilities\n0.00\n1\n0.00\n0.00\n0.00\n0.00\n0.00\n0.33\n25\n0.244\n\n\n\nCrisis & risk management\n0.00\n1\n0.00\n1.00\n0.00\n0.56\n0.00\n0.85\n18\n0.631\n\n\n\nDigital services\n0.00\n1\n0.00\n0.00\n0.00\n0.74\n0.00\n0.58\n29\n0.444\n\n\n\nFiscal & financial management\n0.40\n1\n0.50\n1.00\n0.42\n0.67\n0.44\n0.89\n19\n0.783\n\n\n\nHR management\n0.60\n1\n0.00\n0.44\n0.28\n0.57\n0.29\n0.67\n34\n0.640\n\n\n\nInclusiveness\n0.63\n1\n0.20\n0.60\n0.30\n0.57\n0.38\n0.72\n30\n0.663\n\n\n\nIntegrity\n0.78\n1\n0.00\n0.18\n0.43\n0.53\n0.40\n0.57\n14\n0.526\n\n\n\nOpenness\n0.30\n1\n0.30\n1.00\n0.25\n0.78\n0.28\n0.93\n22\n0.818\n\n\n\nPolicy making\n1.00\n1\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n38\n1.000\n\n\n\nProcurement\n0.00\n1\n0.00\n0.50\n0.00\n0.67\n0.00\n0.72\n18\n0.513\n\n\n\nRegulation\n0.35\n1\n0.33\n1.00\n0.33\n0.89\n0.34\n0.96\n34\n0.908\n\n\n\nTax administration\n0.50\n1\n0.33\n1.00\n0.22\n0.56\n0.35\n0.85\n24\n0.770\n\n\n\n\nTable 2.8.A in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n Mean DQA ≥ 0.75\n Mean DQA 0.75-0.25\n Mean DQA &lt; 0.25\n\nWe can also see in Table 2.6 that there is noticeable variation in the number of countries that achieve the maximum overall data quality score for each indicator. For policy making all 38 countries score achieve the maximum score, while for integrity only 14 countries achieve the maximum score.\nBesides integrity, three other indicators (crisis & risk management, fiscal & financial management, and procurement) have less than 20 countries achieving the maximum score, while three indicators besides policy making have more than 30 countries achieving the maximum score (HR management, inclusiveness, and regulation).\nThe indicator data quality scores can also be used to create a data-driven red-amber-green (RAG) rating for data quality. Using the mean overall data quality scores for each indicator from the 38 countries selected for the 2019 edition of InCiSE, a ‘green’ rating is assigned to those with a score of 0.75 or higher, ‘amber’ to those with a score between 0.25 and 0.75, and ‘red’ to those with a score below 0.25.\nHowever, the data quality assessment does not consider the reliability and validity of each indicator’s construction and therefore says nothing on how well the indicator represents the concept it is trying to measure. Instead, these data-driven RAG ratings can be combined with a subjective assessment of wider data quality concerns to make an overall assessment of the general ‘quality’ of each indicator. Table 2.7 shows the data quality assessment of each indicator alongside a high-level qualitative assessment of the indicator and a ‘final’ subjective RAG rating for the indicator.\n\n\n\n\nTable 2.7: Overall quality assessment ‘RAG’ rating of the 2019 InCiSE indicators\n\n\nInCiSE indicator\nMean DQA score\nNumber of metrics\nDQA-based RAG rating\nHigh-level assessment of the reliability and validity of the indicator construction\nFinal RAG rating\n\n\n\n\nPolicy making\n1.000\n8\n\nThe indicator uses a wide range of metrics that give a broad overview of the concept, however these come from a single source relying on external expert perception.\n\n\n\nRegulation\n0.908\n3\n\nThe indicator contains a number of metrics which appear to give a detailed overview of the concept.\n\n\n\nOpenness\n0.818\n10\n\nThe indicator uses a large number of metrics from a wide range of sources that give a broad overview of the concept.\n\n\n\nFiscal & financial management\n0.783\n6\n\nThe indicator contains a number of metrics which appear to give a detailed overview of the concept.\n\n\n\nTax administration\n0.770\n6\n\nThe indicator has a small number of metrics that give an overview of some aspects of the concept.\n\n\n\nInclusiveness\n0.663\n5\n\nThe indicator has only a small number of metrics which only provide a partial picture of performance across the concept.\n\n\n\nHR management\n0.640\n9\n\nThe indicator's metrics give an overview of some aspects of the concept, but several metrics are dependent on external perceptions and public sector proxy data.\n\n\n\nCrisis & risk management\n0.631\n13\n\nThe indicator contains a wide range of metrics which provide a broad overview of the concept, however one of the two data sources focuses solely on natural disaster risk management.\n\n\n\nIntegrity\n0.536\n17\n\nThe indicator has a large number of metrics that give a broad overview of the concept, however it relies heavily on external expert perceptions.\n\n\n\nProcurement\n0.513\n6\n\nThe indicator has a small number of metrics that give an overview of some aspects of the concept.\n\n\n\nDigital services\n0.444\n13\n\nThe indicator relies on a number of metrics from a single source which gives an overview of some aspects of the concept and relies on public sector proxy data.\n\n\n\nCapabilities\n0.244\n14\n\nWhile the indicator has a large number of metrics, these are all drawn from a public sector proxy and date between 2012-2015.\n\n\n\nIT for officials\n\n\n\nNo data available: indicator not measured.\n\n\n\nInnovation\n\n\n\nNo data available: indicator not measured.\n\n\n\nInternal finance\n\n\n\nNo data available: indicator not measured.\n\n\n\nSocial security administration\n\n\n\nThe social security administration indicator has been depreciated following an in-depth review.\n\n\n\nStaff engagement\n\n\n\nNo data available: indicator not measured.\n\n\n\n\nTable 2.8.B in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n Green rating icon\n Amber rating icon\n Red rating icon\n X rating icon\n\nFive of the indicators have a mean data quality score of 0.75 or higher, earning them an initial ‘green’ rating. Of these indicators, three retain their green rating after wider considerations of the quality of the indicators are taken into account, meaning that these indicators are considered to provide broad and robust coverage of their respective concepts. Two of the five are demoted from green to amber, reflecting concerns about whether the indicators are sufficiently broad.\nSix of the indicators have an initial ‘amber’ rating. Five of these indicators retain their rating, meaning they may only provide partial coverage of the underlying concept or be heavily reliant on one particular data source or type of data. One of the six is demoted from amber to red, reflecting concerns that the indicator provides limited coverage of the underlying concept.\nOne indicator has an initial ‘red’ rating, which is driven largely by its lack of recent data and being solely composed of public sector proxy data. Finally, the social security function, which was included in the 2017 Pilot, is given a ‘red’ rating following its removal from the 2019 edition of InCiSE due to data quality concerns. This change is discussed further in Chapter 15 and Chapter 17.\n\n\n2.8.2 Quality of country-level results\nCountry-level data quality has already been considered to some degree, through the determination of country selection in Section 2.3. However, as with the quality of indicators, the results of the data quality assessment can be used to show the relative quality of the selected countries, which can help improve interpretation of the results of the InCiSE Index.\nTable 2.8 presents a detailed overview of the data quality by country. Each country has been given an overall data quality letter “grade” based on its overall data quality score, and for each indicator each country has been given a “RAG” rating.\nThe overall data quality grades are allocated as follows based on a country’s data quality score rounded to 2 decimal places:\n\nA+ for those countries that achieve the highest overall data quality assessment score (i.e. a data quality score of 0.75 when rounded to 2 decimal places)\nA for countries with a data quality score greater than or equal to 0.7 but less than 0.75\nB for countries with a data quality score greater than or equal to 0.65 but less than 0.7\nC for countries with a data quality score greater than or equal to 0.6 but less than 0.65\nD for countries with a data quality score greater than or equal to 0.5 but less than 0.6\n\nFor the indicators, a four category “RAG+” rating system is adopted. The data quality scores have been normalised (using min-max normalisation) by indicator:\n\nA ‘green’ rating is given to those countries with a normalised indicator data quality score of 1 – the country has the best possible data for this indicator.\nAn ‘amber’ rating is given to those countries with a normalised indicator data quality score of greater than or equal to 0.5 – the country’s data quality is at least half as good as the ‘best’ possible data for that indicator.\nA ‘red’ rating is given to those countries with a normalised indicator data quality score of less than 0.5 – the country’s data quality is less than half as good as the’best’ possible data for that indicator.\nAn ‘X’ rating is given to those countries which have no data at all for that metric – that all of the country’s scores for the metrics in that indicator have been imputed.\n\n\n\n\n\nTable 2.8: Data quality scores by indicator and country\n\n\nCountry\nOverall data quality score\nData quality grade\nPercent of metrics available\nCAP\nCRM\nDIG\nFFM\nHRM\nINC\nINT\nOPN\nPOL\nPRO\nREG\nTAX\n\n\n\n\nGBR\n0.757\nA+\n100%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nITA\n0.755\nA+\n99%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOL\n0.755\nA+\n99%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSWE\n0.755\nA+\n99%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNOR\n0.752\nA+\n99%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSVN\n0.750\nA\n99%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUT\n0.738\nA\n98%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFIN\n0.736\nA\n97%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nESP\n0.733\nA\n97%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNLD\n0.731\nA\n98%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFRA\n0.718\nA\n97%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPRT\n0.716\nA\n85%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNK\n0.707\nA\n93%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDEU\n0.701\nA\n96%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRC\n0.696\nB\n94%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSVK\n0.692\nB\n93%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHUN\n0.671\nB\n81%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEST\n0.669\nB\n90%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCZE\n0.659\nB\n90%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTUR\n0.650\nC\n90%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMEX\n0.648\nC\n73%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNZL\n0.644\nC\n83%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHL\n0.643\nC\n79%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCAN\n0.638\nC\n78%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKOR\n0.636\nC\n78%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBEL\n0.635\nC\n85%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLVA\n0.628\nC\n75%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHE\n0.627\nC\n79%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUS\n0.618\nC\n71%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLTU\n0.615\nC\n82%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIRL\n0.614\nC\n84%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJPN\n0.597\nD\n75%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUSA\n0.579\nD\n74%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nISR\n0.578\nD\n72%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nISL\n0.563\nD\n68%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nROU\n0.529\nD\n66%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBGR\n0.511\nD\n66%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHRV\n0.501\nD\n65%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2.3.C in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n Green rating icon\n Amber rating icon\n Red rating icon\n X rating icon\n\nTable 2.8 reveals interesting patterns in data quality:\n\nSix countries are given an “A+” rating – one has full data for all indicators (i.e. all indicator rated ‘green’), while the other five have just one indicator where they have an ‘amber’ rating.\nEight countries achieve an “A” rating – they have generally good coverage of data but typically have two or three indicators rated ‘amber’ or ‘red”, only one country has an indicator where all data for that indicator has been imputed (rated’grey’).\nSeven countries achieve a “B” rating for data quality – these countries have a greater degree of ‘amber’ and ‘red’ rated indicators, typically four. All but one country has at least one ‘red’ rated indicator, one country has one indicator fully imputed while another has two indicators fully imputed.\nTen countries achieve a “C” rating for data quality – all countries have at least one ‘red’ rated indicator and eight of the countries have at least one indicator fully imputed.\nSeven countries achieve a “D” rating for data quality – all countries both have at least one indicator fully imputed and one indicator rated ‘red’, four countries have at least four indicators rated ‘red’."
  },
  {
    "objectID": "02_index.html#sec-time-series",
    "href": "02_index.html#sec-time-series",
    "title": "2  Methodology of the InCiSE index",
    "section": "2.9 Comparisons over time",
    "text": "2.9 Comparisons over time\nThe InCiSE project is still in its infancy, and the methodology for the 2019 Index has built substantially on the foundations of the 2017 Pilot – most of the metrics used in the 2017 Pilot have continued to be used in the 2019 edition. Of the 70 metrics in the 2017 Pilot that are directly comparable to the 2019 edition, 33 have since had updates which are incorporated into the model.\nIn addition to the 70 metrics carried over from the 2017 Pilot, a further 46 metrics have been incorporated into the InCiSE methodology, bringing the total number of metrics for the 2019 model to 116. Most of these additional metrics (30) are from existing sources. Some have been collected multiple times, but some are new and have no previous data collection. Changes are summarised in Chapter 15.\nA further consideration for comparisons over time is the need to deal with different reference dates and frequencies of updating.\nSome data is updated on an annual basis while others are on two-year, three-year, or longer update cycles. For example, the data for capabilities has not been updated since it was first collected in 2012. These differing cycles are the function of a variety of different factors, such as an appreciation of the pace of change within a given topic area or the funding and resourcing of the data producers.\nAs outlined in Section 2.4, the InCiSE model uses imputation methods which use statistical techniques to provide an estimate of a country’s missing data. While the imputation is based on predictive methods, it is not a firm prediction of what a given country would have scored, but better understood as indicative. The imputation methods may change between years, and the relationships in the observed data (from which the imputation is drawn) may also change, limiting the reliability of comparing data imputed in one year with data imputed in another year.\nIt may also be the case that at one time point a country did not have data for a given metric but then has data at a later time point (or vice versa). This would mean that for one point the metrics would have been imputed.\nComparing a score based on ‘real’ data with one based on imputed estimates is unlikely to be reliable. In addition, as the methodology for InCiSE develops, future versions of the InCiSE Index could adopt back-/forward-casting (i.e. using results from different time points) to improve the quality of the imputation methods. This would also make time-series comparison more complicated or less feasible.\nFinally, consideration should be given to the changing country composition. The 2017 Pilot covered 31 countries, while the 2019 edition covers 38 countries. As outlined in section Section 2.5, the data is normalised so that country scores are relative to the group of countries selected. This again means it is not possible to directly compare scores from one edition of InCiSE to another as the scores are related to the specific data range and country set used for that edition.\nAs a result of these varied challenges, the InCiSE Partners have decided not to include any comparisons between the 2017 Pilot and the 2019 edition of the InCiSE Index.\nFurthermore, the Partners strongly advise against any direct or indirect comparisons being made beyond references to changes in the underlying source data itself (i.e. before the data is imported into the InCiSE data model, processed, imputed and normalised).\n\n\n\n\nArel-Bundock, V., Enevoldsen, N. & Yetman, C.J. (2018). Countrycode: An R package to convert country names and country codes. Journal of Open Source Software 3(28): 848. Retrieved from https://doi.org/10.21105/joss.00848\n\n\nOECD, European Union & Joint Research Centre - European Commission. (2008). Handbook on Constructing Composite Indicators: Methodology and User Guide. Organisation for Economic Cooperation; Development. Retrieved from https://www.oecd-ilibrary.org/economics/handbook-on-constructing-composite-indicators-methodology-and-user-guide_9789264043466-en\n\n\nvan Buuren, S. (2018). Flexible Imputation of Missing Data, Second Edition (2nd ed.). Second edition.  Boca Raton, Florida : CRC Press, [2019] : Chapman; Hall/CRC. Retrieved from https://www.taylorfrancis.com/books/9780429492259\n\n\nvan Buuren, S. & Groothuis-Oudshoorn, K. (2011). Mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software 45(3): 1–67."
  },
  {
    "objectID": "03_00_indicators.html",
    "href": "03_00_indicators.html",
    "title": "Methodology of the InCiSE indicators",
    "section": "",
    "text": "The sections of this chapter set out the methodology for each of the 12 indicators that make up the 2019 edition of the InCiSE Index. For each indicator the section outlines: the source data; the indicator structure and weighting; the nature and definition of the imported source data and any transformations; the approach to imputation of missing data; and, the rationale for any changes from the 2017 Pilot methodology.\nThe source data for InCiSE comes from a variety of sources which use different methodologies, we have applied the following taxonomy to describe the different types of data sources:\n\nSubjective data:\n\nPublic opinion survey – a survey of the opinion/attitudes of the general population/households within a country (e.g. Transparency International’s Global Corruption Barometer)\nBusiness opinion survey – a survey of the opinion/attitudes of business owners/executives within a country (e.g. the World Economic Forum’s Executive Opinion Survey)\nExpert assessment – a survey/assessment of a country made by a small number of experts/researchers (e.g the Quality of Government Institute’s Expert Opinion Survey)\n\nObjective data:\n\nAnalysis of published data – secondary analysis of information/data published by governments\nSocial survey – studies that use scientific social survey methods to collect representative information about the population, but are not opinion surveys (e.g. the OECD’s Programme for the International Assessment of Adult Skills)\nGovernment assessments – official responses from governments to data collection exercises by international organisations (e.g. OECD surveys)\n\n\nEach of these types has its strengths and limitations, and some types of data are more appropriate in certain cases than others. The InCiSE model places equal value on these different types of data and does not attempt to make ‘quality adjustments’, e.g. through weighting, to distinguish between the different types of data.\nCritiques of subjective measures can include that they measure perceptions and other ‘subjective’ positions which may be influenced by considerations beyond just the specific item being measured – e.g. business perceptions of how effective the civil service is at delivering services may be influenced by their perceptions of how business-friendly the government’s political programme is. Another critique is through the use of expert assessments, which often rely on a small number of experts/researchers to assess government performance on a given topic or area. However, expert assessments often focus on niche areas which the general public/businesses may not be able to make a judgement about.\nObjective data is also not without its own limitations. It can be argued that it is rare for any data to be truly ‘objective’ even if it is not directly ‘subjective’. Even if the data does not aim to measure perceptions or another form of subjective position, it is collected and analysed to fulfil a particular purpose, defined by a particular group of individuals, with a particular agenda. While efforts can be made to minimise biases and particular normative assumptions, in any study there are implicit or explicit subjective decisions made about the collection and analysis of data. The decisions a researcher or analyst makes, such as whether to collect one piece of data over another, which methods of collection and analysis to use, or what to consider in scope or out of scope, are all subjective and therefore will influence the results.\nEach of the chapters in this part (3-14) list the data sources used to supply the input data for the InCiSE metrics of each indicator. For ease of reference in each section’s tables, the data sources are given an acronym. Figures in square brackets next to a data source indicate the reference year for the data (i.e. the year the data was collected/relates to) rather than the year of publication. A complete reference list of the data sources used for InCiSE is provided in the References chapter. Some metrics are calculated as aggregations of multiple data points, details of these calculations are provided in Appendix A.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThe introductory text on this page and Chapters 3-14 of this web book were presented as a single chapter (Chapter 3) in the original 2019 publication. For improved navigation and readability this part of the report has been split into separate chapters. Footnotes have been added to charts, tables and chapters to indicate the resulting differences in numbering between this web book and the original PDF publication."
  },
  {
    "objectID": "03_01_integrity.html#sec-integrity-imputation",
    "href": "03_01_integrity.html#sec-integrity-imputation",
    "title": "3  Integrity",
    "section": "3.1 Imputation of missing data",
    "text": "3.1 Imputation of missing data\nNone of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the integrity metrics. As a result the imputation of missing data for the integrity metrics is based solely on the data within the indicator."
  },
  {
    "objectID": "03_01_integrity.html#sec-integrity-changes",
    "href": "03_01_integrity.html#sec-integrity-changes",
    "title": "3  Integrity",
    "section": "3.2 Changes from the 2017 pilot",
    "text": "3.2 Changes from the 2017 pilot\nThere is one proposed change to the structure of the metrics used in the calculation of the integrity indicator: the inclusion of a measure from the Bertelsmann Foundation’s Sustainable Governance Indicators on corruption prevention.\nA further change from the 2017 pilot methodology has been implemented in the processing of the OECD’s data on post-employment cooling-off periods. The model now simply codes whether post-employment cooling-off periods and now ignores whether compensation is paid during this period.\nThe OECD source data provides information on whether post-employment cooling-off periods exist for both senior civil servant sand other civil servants, and also includes information on whether a compensation period is paid during that period.\nThese data are combined by the InCiSE model into a single scale, outlined below. In the 2017 Pilot, this scale creates the normative conditions that a post-employment cooling-off period with compensation for both groups of civil servants is “best” and no cooling-off period is “worst”, Table 3.2.\n\n\n\n\nTable 3.2: Coding of post-employment cooling-off in the 2017 Pilot edition of InCiSE\n\n\nInCiSE 2017 post-employment scale value\nSenior civil servants\nOther civil servants\n\n\nCooling-off period?\nWith compensation?\nCooling-off period?\nWith compensation?\n\n\n\n\n4\nYes\nYes\nYes\nYes\n\n\n3\nYes\nYes\nYes\nNo\n\n\nYes\nNo\nYes\nYes\n\n\n2\nYes\nYes\nNo\nN/A\n\n\nNo\nN/A\nYes\nYes\n\n\nYes\nNo\nYes\nNo\n\n\n1\nYes\nNo\nNo\nN/A\n\n\nNo\nN/A\nYes\nNo\n\n\n0\nNo\nN/A\nNo\nN/A\n\n\n\nTable 3.1.C in the original 2019 publication\n\n\n\n\n\n\n\nFurther examination of the data, as reported by the OECD, showed that only a limited number of officials in only a small number of countries received paid compensation during a cooling off period and that there was noticeable variation in how this was decided by country. This limited usage of post-employment compensation and high variability in its nature suggests that it may not be appropriate to code in the provision of post-employment compensation as normative “best” practice in the calculation of the integrity indicator.\n\n“During the cooling off period, only some categories of public officials in Austria, Israel, Norway, Portugal and Spain receive compensation. For instance, in Spain, public officials receive 80% of their basic salaries as compensation and in Norway, compensation is awarded only for prohibitions on taking up a specific appointment, the level of which is equivalent to the salary received at the time of the public official left public office” (OECD, 2015, p. 116)\n\nTherefore, for the 2019 edition, InCiSE has adopted a new scale that measures only the existence of post-employment cooling-off periods for senior civil servants and other civil servants, ignoring the use/existence of compensation, Table 3.3. The highest score will be awarded for those countries that have a cooling-off period for both groups of civil servants, the lowest score for those that do not have a cooling-off period for either group, while an intermediate score will be given to those countries that have a cooling-off period for one group but not the other – with cooling-off periods for senior civil servants preferred to those for non-senior civil servants.\n\n\n\n\nTable 3.3: Coding of post-employment cooling-off in the 2019 edition of InCiSE\n\n\nInCiSE 2019 post-employment scale value\nDoes a post-employment cooling-off period exist for...?\n\n\nSenior civil servants\nOther civil servants\n\n\n\n\n3\nYes\nYes\n\n\n2\nYes\nNo\n\n\n1\nNo\nYes\n\n\n0\nNo\nNo\n\n\n\nTable 3.1.D in the original 2019 publication\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.1 in the original 2019 publication.\n\n\n\n\n\n\nInternational Civil Service Commission. (2002). Standards of conduct for the international civil service. New York: United Nations. Retrieved from https://icsc.un.org/resources/pdfs/general/standards.pdf\n\n\nMuriithi, K., Jimenez, M., Jannin, N., Sajid, N., Singh, S. & Sharma, S. (2015). Quantifying Governance: An indicator-based approach. London: LSE/DFID.\n\n\nOECD. (2015). Government at a Glance 2015. Paris: Organisation for Economic Cooperation; Development. Retrieved from https://www.oecd-ilibrary.org/governance/government-at-a-glance-2015_gov_glance-2015-en"
  },
  {
    "objectID": "03_02_openness.html#sec-openness-imputation",
    "href": "03_02_openness.html#sec-openness-imputation",
    "title": "4  Openness",
    "section": "4.1 Imputation of missing data",
    "text": "4.1 Imputation of missing data\nNone of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the openness metrics. As a result the imputation of missing data for the openness metrics is based solely on the data within the indicator."
  },
  {
    "objectID": "03_02_openness.html#sec-openness-changes",
    "href": "03_02_openness.html#sec-openness-changes",
    "title": "4  Openness",
    "section": "4.2 Changes from the 2017 Pilot",
    "text": "4.2 Changes from the 2017 Pilot\nCompared to the 2017 Pilot, an additional metric from the Bertelsmann Sustainable Governance Indicators on access to information has been identified and added to the indicator.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.2 in the original 2019 publication.\n\n\n\n\n\n\nGraham, J., Amos, B. & Plumptre, T. (2003). Principles for good governance in the 21st century (policy brief no. 15). Ottawa: Institute on Governance.\n\n\nUnited Nations. (1999). Transparency in Government. Retrieved from http://unpan1.un.org/intradoc/groups/public/documents/un/unpan012062.pdf\n\n\nWorld Bank. (2017). World Development Report 2017. Washington DC: The World Bank."
  },
  {
    "objectID": "03_03_capabilities.html#sec-capabilities-imputation",
    "href": "03_03_capabilities.html#sec-capabilities-imputation",
    "title": "5  Capabilities",
    "section": "5.1 Imputation of missing data",
    "text": "5.1 Imputation of missing data\nOf the 38 countries selected for the 2019 edition of InCiSE, 10 countries do not have data for the capabilities metrics. As there are countries where data is missing for all metrics the imputation of the capabilities indicator requires a data point from outside the indicator. The 2017 edition of InCiSE used data from the HR Management indicator on applicant skills and whether a country was an EU member. For the 2019 edition, the applicant skills metric from the HR management indicator is retained, but EU membership is removed. One of the metrics within the indicator is the level of tertiary educational attainment. There are a number of sources for estimates of tertiary educational attainment in the general adult population of most countries. Therefore, InCiSE also uses UNESCO data on educational attainment to impute missing data for the capabilities indicator."
  },
  {
    "objectID": "03_03_capabilities.html#sec-capabilities-changes",
    "href": "03_03_capabilities.html#sec-capabilities-changes",
    "title": "5  Capabilities",
    "section": "5.2 Changes from the 2017 Pilot",
    "text": "5.2 Changes from the 2017 Pilot\nThe capabilities indicator published in the2019 edition of InCiSE has had a number of changes which improve its quality compared to the data published in the 2017 Pilot. These include additional metrics, change in how data is extracted, updated coding of educational attainment, and changes to imputation. While these do not change the recency of the data, they improve the overall quality of the information provided by the indicator. The OECD intends to update PIAAC every decade, as annual change in the skill level of the adult population does not change rapidly – a general principle in education research is that educational attainment is broadly fixed after young adulthood1. Figure 3.1, shows how the overall proportion of tertiary educational attainment has evolved for different age groups since 1997 in four countries, the average annual change is 0.9 percentage points.1 Lutz et al. (2007) and Goujon et al. (2016) utilise this principle to develop “back-projections” of educational attainment, and hold a general assumption that ‘transition’ to different levels of education tend to be limited after the age of 34.\n\n\n\nFigure 5.1: Tertiary education levels of adults 25-34 and 55-64, in selected countries\n Four line graphs showing the proportion of adults with teritary eduation (e.g. a university Bachelor's degree) between 1997 and 2017 for those aged 25 to 34 years old and those aged 55-64 years old in each of Canada, France, Japan and Sweden. The graph shows a broadly linear increase in attainment levels for each age group and a consistent gap between age-groups.                                                                                                                                                                                                                                                                                                                                             Canada                  France                  Japan                  Sweden   1997 2002 2007 2012 2017 1997 2002 2007 2012 2017 1997 2002 2007 2012 2017 1997 2002 2007 2012 2017 0.0% 10.0% 20.0% 30.0% 40.0% 50.0% 60.0%                 Canada 25-34 years Canada 55-64 years France 25-34 years France 55-64 years Japan 25-34 years Japan 55-64 years Sweden 25-34 years Sweden 55-64 years   Source: OECD (2023), Population with tertiary education. doi: 10.1787/0b8f90e9-en (Accessed on 28 November 2023). This chart varies slightly from that included in the original published PDF report due to changes in data availability. The original chart included data for the age groups 25-34, 35-44 and 45-54, however the source data at the time of this reproduction (November, 2023) provides data for those aged 25-35 and 55-64. This chart was Figure 3.1 in the original 2019 publication\n\n\n\n\n5.2.1 Additional metrics\nIn examining the PIAAC dataset, a number of additional metrics that complement the metrics used in the pilot provide a richer picture of capabilities in the public administration workforce.\nThe pilot metrics gave a broad overview of employee capability, looking at overall levels of core skills (literacy, numeracy and problem solving) and tertiary educational attainment. The additional metrics complement this by providing for measurement of the use of core skills at work (ICT, numeracy, reading and writing). They also cover more complex skills, including influencing others, planning, and task management. Finally, they also include metrics relating to learning and development — whether individuals learn at work, their overall attitude to learning, and whether they have participated in learning for work-related purposes (either formallyor informally). Together these metrics provide a more detailed picture of the skills and capabilities of the workforce.\n\n\nUsing the public administration industrial sector\nThe pilot edition of InCiSE used data for all adults currently employed by a public sector organisation. Further investigations of the raw data in PIAAC indicated that there was a sufficient sample size in most countries (n&gt;100) to generate an estimate for the “public administration” industry sector2 and worked for a public sector organisation.2 Sample sizes for the public administration industry sector (limited to declared public sector workers) range from 83 to 1,562. The minimum and maximum are both noticeable outliers: ignoring these, the sample sizes range from 144-446. The only country with a sample less than 100 (Russian Federation) had similar standard errors to those of other countries and therefore was retained in the data extracted from PIAAC.\nThere is a considerable difference between countries with regard to whether someone is a public sector worker. This is in part due to the political choices about what is or isn’t delivered by the public sector. For example, in the United Kingdom the vast majority of healthcare workers will be public sector employees, while in the United States the vast majority of healthcare workers will be private sector employees. In contrast, this difference is likely to be much reduced for the “public administration” industry sector, as it will not include sectors such as healthcare, education or competitive market economic sectors. Therefore, while the sample size for the “public administration” subset will be lower, it is likely to be a more appropriate comparator group across countries than using the large “public sector” basis.\nFurther details on the structure of the activities included in the “public administration” industrial sector can be found in the UN’s registry of Statistical Classifications (UNSD, 2018).\n\n\n5.2.2 Updated coding of tertiary education\nIn reviewing the way that results are extracted from PIAAC’s raw data files, an improvement was identified in the way tertiary education is coded. The pilot edition of InCiSE used data from a variable included for legacy comparisons with previous international assessments of adult competencies based on type of institution attended. InCiSE 2019 uses a more accurate method based on the highest level of qualification achieved.\n\n\n5.2.3 Updating the approach to imputation\nIn the pilot edition of InCiSE, missing data issues were handled by examining the relationship of the metrics from PIAAC with metrics from the other indicators in InCiSE (as PIAAC is the only data source for the capabilities indicator). The most suitable predictors observed in the dataset were the applicant skills metric from the HR management indicator and whether a country was an EU member. As described above, the imputation for the 2019 edition has changed the methodology to remove the EU membership criteria and include the tertiary education level of the general population in the external imputation data. This provides a closer link to the indicator’s theoretical construct.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.3 in the original 2019 publication.\n\n\n\n\n\n\nFukuyama, F. (2013). What Is Governance? Governance 26(3): 347–368. Retrieved from https://onlinelibrary.wiley.com/doi/10.1111/gove.12035\n\n\nGoujon, A., K. C., S., Speringer, M., Barakat, B., Potancoková, M., Eder, J., … Lutz, W. (2016). A Harmonized Dataset on Global Educational Attainment Between 1970 And 2060 – An Analytical Window into Recent Trends and Future Prospects in Human Capital Development. Journal of Demographic Economics 82(3): 315–363. Retrieved from https://www.cambridge.org/core/product/identifier/S2054089216000109/type/journal_article\n\n\nLutz, W., Goujon, A., K. C., S. & Sanderson, W. (2007). Reconstruction of Populations by Age, Sex and Level of Educational Attainment for 120 Countries for 1970-2000 (IIASA Interim Report). Laxenburg, Austria: International Institute for Applied Systems Analysis. Retrieved from http://pure.iiasa.ac.at/8453\n\n\nOPM & CIPFA. (2004). The Good Governance Standard for Public Services. London: The Independent Commission on Good Governance in Public Services.\n\n\nUNSD. (2018). Statistical Classifications. Retrieved from https://unstats.un.org/unsd/class/default.asp"
  },
  {
    "objectID": "03_04_inclusiveness.html#sec-inclusiveness-imputation",
    "href": "03_04_inclusiveness.html#sec-inclusiveness-imputation",
    "title": "6  Inclusiveness",
    "section": "6.1 Imputation of missing data",
    "text": "6.1 Imputation of missing data\nNone of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the inclusiveness metrics. As a result the imputation of missing data for the inclusiveness metrics is based solely on the data within the indicator."
  },
  {
    "objectID": "03_04_inclusiveness.html#sec-inclusiveness-changes",
    "href": "03_04_inclusiveness.html#sec-inclusiveness-changes",
    "title": "6  Inclusiveness",
    "section": "6.2 Changes from the 2017 Pilot",
    "text": "6.2 Changes from the 2017 Pilot\nThere are no changes in the structure of the inclusivness indicator from the 2017 Pilot.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.4 in the original 2019 publication.\n\n\n\n\n\n\nInternational Civil Service Commission. (2002). Standards of conduct for the international civil service. New York: United Nations. Retrieved from https://icsc.un.org/resources/pdfs/general/standards.pdf\n\n\nOECD. (n.d.). Building more effective, accountable, and inclusive institutions for all. Paris. Retrieved from https://www.oecd.org/dac/post-2015.htm\n\n\nOECD. (2015). Government at a Glance 2015. Paris: Organisation for Economic Cooperation; Development. Retrieved from https://www.oecd-ilibrary.org/governance/government-at-a-glance-2015_gov_glance-2015-en\n\n\nOPM & CIPFA. (2004). The Good Governance Standard for Public Services. London: The Independent Commission on Good Governance in Public Services."
  },
  {
    "objectID": "03_05_policy_making.html#sec-policy-imputation",
    "href": "03_05_policy_making.html#sec-policy-imputation",
    "title": "7  Policy making",
    "section": "7.1 Imputation of missing data",
    "text": "7.1 Imputation of missing data\nAll 38 countries selected for the 2019 edition of InCiSE have data for all the metrics in the policy making indicator. Therefore, no approach to imputation is needed."
  },
  {
    "objectID": "03_05_policy_making.html#sec-policy-changes",
    "href": "03_05_policy_making.html#sec-policy-changes",
    "title": "7  Policy making",
    "section": "7.2 Changes from the 2017 Pilot",
    "text": "7.2 Changes from the 2017 Pilot\nThe policy making indicator is unchanged from the 2017 Pilot edition.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.5 in the original 2019 publication.\n\n\n\n\n\n\nKaufman, D., Kraay, A. & Zoido-Lobatón, P. (1999). Governance Matters (Policy Research Working Paper No. 2196). Retrieved from https://ssrn.com/abstract=188568\n\n\nOPM & CIPFA. (2004). The Good Governance Standard for Public Services. London: The Independent Commission on Good Governance in Public Services."
  },
  {
    "objectID": "03_06_fiscal_financial.html#sec-fiscal-imputation",
    "href": "03_06_fiscal_financial.html#sec-fiscal-imputation",
    "title": "8  Fiscal and financial management",
    "section": "8.1 Imputation of missing data",
    "text": "8.1 Imputation of missing data\nNone of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the fiscal and financial management metrics. As a result the imputation of missing data for the fiscal and financial management metrics is based solely on the data within the indicator."
  },
  {
    "objectID": "03_06_fiscal_financial.html#sec-fiscal-changes",
    "href": "03_06_fiscal_financial.html#sec-fiscal-changes",
    "title": "8  Fiscal and financial management",
    "section": "8.2 Changes from the 2017 Pilot",
    "text": "8.2 Changes from the 2017 Pilot\nThe fiscal and financial management indicator has seen the introduction of three new data points to increase the scope and robustness of the indicator. These include a metric on the publication of medium-term budgeting data from the World Bank into the theme of the same name and two new metrics under the economic appraisal and evaluation theme: two data points measuring the extent of external scrutiny or audit and two data points measuring the extent of transparency based on the publication of budgetary reports.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.6 in the original 2019 publication.\n\n\n\n\n\n\nHolt, J. & Manning, N. (2014). Fukuyama Is Right about Measuring State Quality: Now What? Governance 27(4): 717–728. Retrieved from https://onlinelibrary.wiley.com/doi/10.1111/gove.12109\n\n\nOECD. (2015). Recommendation of the Council on Budgetary Governance (explanatory note). Paris: Organisation for Economic Cooperation; Development. Retrieved from http://www.oecd.org/gov/budgeting/Recommendation- of-the-Council-on-Budgetary-Governance.pdf\n\n\nWorld Bank. (2012). Indicators of the Strength of Public Management Systems: A key part of the Public Sector results story. Washington DC: The World Bank. Retrieved from http://siteresources.worldbank.org/PUBLICSECTORANDGOVERNANCE/ Resources/285741-1354024300711/ISPMS.pdf"
  },
  {
    "objectID": "03_07_regulation.html#sec-regulation-imputation",
    "href": "03_07_regulation.html#sec-regulation-imputation",
    "title": "9  Regulation",
    "section": "9.1 Imputation of missing data",
    "text": "9.1 Imputation of missing data\nNone of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the regulation metrics. As a result the imputation of missing data for the regulation metrics is based solely on the data within the indicator."
  },
  {
    "objectID": "03_07_regulation.html#sec-regulation-changes",
    "href": "03_07_regulation.html#sec-regulation-changes",
    "title": "9  Regulation",
    "section": "9.2 Changes from the 2017 Pilot",
    "text": "9.2 Changes from the 2017 Pilot\nThe regulation indicator has had three additional metrics added from the Bertelsmann Foundation’s Sustainable Governance Indicators on the use and quality of regulatory impact assessments (RIA), and whether RIAs include sustainability checks.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.7 in the original 2019 publication.\n\n\n\n\n\n\nBoviard, T. & Löffler, E. (2003). Public Management and Governance. London: Routledge.\n\n\nInternational Monetary Fund. (2016). Consultation on the IMF Guidelines on Governance Issues. Retrieved from https://www.imf.org/external/np/exr/consult/2016/governance/\n\n\nOECD. (2012). Recommendation of the Council on Regulatory Policy and Governance (explanatory note). Paris: Organisation for Economic Cooperation; Development. Retrieved from http://www.oecd.org/gov/regulatory-policy/49990817.pdf"
  },
  {
    "objectID": "03_08_crisis_risk.html#sec-crisis-imputation",
    "href": "03_08_crisis_risk.html#sec-crisis-imputation",
    "title": "10  Crisis and risk management",
    "section": "10.1 Imputation of missing data",
    "text": "10.1 Imputation of missing data\nOne of the 38 countries selected for the 2019 edition of InCiSE has completely missing data for all crisis and risk management metrics. This is an improvement on the 2017 Pilot of InCiSE where eight countries had completely missing data. The 2017 Pilot used median imputation to handle missing data for the crisis and risk management indicator (i.e. replacement of missing values with the median value of the included countries). As a result of the decision to move to fully predictive imputation for the 2019 edition, external predictors needed to be found. There are no easily identifiable external predictors (e.g. tertiary education for capabilities or the UN’s E-Government survey for digital services), instead the correlations between the crisis and risk management metrics and other metrics in the InCiSE model have been analysed to identify potential predictors. This analysis has selected three metrics: the task discretion metric from the capabilities indicator; the use of data in HR administration from the HR management indicator; and, the Open Data Index from the openness indicator."
  },
  {
    "objectID": "03_08_crisis_risk.html#sec-crisis-changes",
    "href": "03_08_crisis_risk.html#sec-crisis-changes",
    "title": "10  Crisis and risk management",
    "section": "10.2 Changes from the 2017 Pilot",
    "text": "10.2 Changes from the 2017 Pilot\nThe 2017 Pilot used data solely from the national monitoring and progress reports of the UN Hyogo Framework for Action. The Hyogo Framework for Action ended in 2015 and has been replaced by the Sendai Framework, however monitoring and reporting of this framework has only just begun. Furthermore, these frameworks focus on natural disaster risk rather than the full range of risks and civil contingencies issues that countries have to manage at a central government level. Since the publication of the pilot a further dataset has become available, the OECD’s Survey of the Governance of Critical Risks. This dataset provides data on this wider array of risks that governments, especially OECD members, tend to manage.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.8 in the original 2019 publication.\n\n\n\n\n\n\nBaubion, C. (2013). OECD Risk Management: Strategic Crisis Management (OECD Working Papers on Public Governance No. 23). Retrieved from https://www.oecd-ilibrary.org/governance/oecd-risk-management_5k41rbd1lzr7-en\n\n\nChristensen, T., Fimreite, A.L. & Lægreid, P. (2011). Crisis Management: The Perceptions of Citizens and Civil Servants in Norway. Administration & Society 43(5): 561–594. Retrieved from http://journals.sagepub.com/doi/10.1177/0095399711412914"
  },
  {
    "objectID": "03_09_procurement.html#sec-procurement-imputation",
    "href": "03_09_procurement.html#sec-procurement-imputation",
    "title": "11  Procurement",
    "section": "11.1 Imputation of missing data",
    "text": "11.1 Imputation of missing data\nTwo of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the procurement indicator.\nThe procurement indicator is a new indicator for the 2019 edition, and there are no easily identifiable external predictors (e.g. tertiary education for Capabilities or the UN’s E-Government survey for Digital Services), instead the correlations between the procurement metrics and the other metrics in the InCiSE model have been analysed to identify potential predictors. This analysis has selected three metrics: the use of data in HR administration from the HR management indicator; the publicised laws metric from the openness indicator; and, the collection cost metric from the tax administration indicator."
  },
  {
    "objectID": "03_09_procurement.html#sec-procurement-changes",
    "href": "03_09_procurement.html#sec-procurement-changes",
    "title": "11  Procurement",
    "section": "11.2 Changes from the 2017 Pilot",
    "text": "11.2 Changes from the 2017 Pilot\nThe procurement indicator is a new indicator and was not covered by the 2017 Pilot edition of the InCiSE Index.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.9 in the original 2019 publication.\n\n\n\n\n\n\nWorld Bank. (2016). Benchmarking Public Procurement 2017. World Bank, Washington, DC. Retrieved from http://hdl.handle.net/10986/32500\n\n\nWorld Trade Organisation. (2015). Government Procurement Agreement: Opening markets and promoting good governance. Retrieved from http://wto.org/english/thewto_e/20y_e/gpa_brochure2015_e.pdf"
  },
  {
    "objectID": "03_10_hrm.html#sec-hrm-imputation",
    "href": "03_10_hrm.html#sec-hrm-imputation",
    "title": "12  HR management",
    "section": "12.1 Imputation of missing data",
    "text": "12.1 Imputation of missing data\nNone of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the HR management metrics. As a result the imputation of missing data for the HR management metrics is based solely on the data within the indicator."
  },
  {
    "objectID": "03_10_hrm.html#sec-hrm-changes",
    "href": "03_10_hrm.html#sec-hrm-changes",
    "title": "12  HR management",
    "section": "12.2 Changes from the 2017 Pilot",
    "text": "12.2 Changes from the 2017 Pilot\nIn the 2017 Pilot, InCiSE used five metrics from the Quality of Governance study. These provided only partial coverage of the topic area, with a particularly strong focus on meritocratic recruitment. Since the 2017 Pilot, the OECD published the 2017 edition of their Government at a Glance report, including a number of measures from their 2016 Survey on Strategic Human Resource Management. The 2019 edition of InCiSE has incorporated three metrics from this survey as published in Government at a Glance in order to improve the coverage of the indicator.\nWhile there continue to be arguments about the use and implementation of performance appraisal and performance-related pay mechanisms within public sector organisations, the OECD (2005) suggests that even if there is no direct performance improvement associated with these measures they can act as a catalyst for change. Thus, there may be secondary effects from performance appraisal and performance related pay that improve civil service effectiveness.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.10 in the original 2019 publication.\n\n\n\n\n\n\nBoviard, T. & Löffler, E. (2003). Public Management and Governance. London: Routledge.\n\n\nFukuyama, F. (2013). What Is Governance? Governance 26(3): 347–368. Retrieved from https://onlinelibrary.wiley.com/doi/10.1111/gove.12035"
  },
  {
    "objectID": "03_11_tax.html#sec-tax-imputation",
    "href": "03_11_tax.html#sec-tax-imputation",
    "title": "13  Tax administration",
    "section": "13.1 Imputation of missing data",
    "text": "13.1 Imputation of missing data\nNone of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the tax administration metrics. As a result the imputation of missing data for the tax administration metrics is based solely on the data within the indicator."
  },
  {
    "objectID": "03_11_tax.html#sec-tax-changes",
    "href": "03_11_tax.html#sec-tax-changes",
    "title": "13  Tax administration",
    "section": "13.2 Changes from the 2017 Pilot",
    "text": "13.2 Changes from the 2017 Pilot\nThere are no changes to the structure of the tax administration indicator.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.11 in the original 2019 publication.\n\n\n\n\n\n\nFukuyama, F. (2013). What Is Governance? Governance 26(3): 347–368. Retrieved from https://onlinelibrary.wiley.com/doi/10.1111/gove.12035\n\n\nOECD. (n.d.). Building more effective, accountable, and inclusive institutions for all. Paris. Retrieved from https://www.oecd.org/dac/post-2015.htm\n\n\nWorld Bank. (2012). Indicators of the Strength of Public Management Systems: A key part of the Public Sector results story. Washington DC: The World Bank. Retrieved from http://siteresources.worldbank.org/PUBLICSECTORANDGOVERNANCE/ Resources/285741-1354024300711/ISPMS.pdf"
  },
  {
    "objectID": "03_12_digital.html#sec-digital-imputation",
    "href": "03_12_digital.html#sec-digital-imputation",
    "title": "14  Digital services",
    "section": "14.1 Imputation of missing data",
    "text": "14.1 Imputation of missing data\nNine of the 38 countries selected for the 2019 edition of InCiSE have completely missing data for the digital services indicator. The 2017 Pilot of the InCiSE Index set out the use of Online Services Index from the UN’s biennial E-Government Survey as the external predictor for imputation. This approach is maintained for the 2019 edition of the InCiSE Index."
  },
  {
    "objectID": "03_12_digital.html#sec-digital-changes",
    "href": "03_12_digital.html#sec-digital-changes",
    "title": "14  Digital services",
    "section": "14.2 Changes from the 2017 Pilot",
    "text": "14.2 Changes from the 2017 Pilot\nThe data source used for the digital services indicator in the 2019 edition of InCiSE is the same as that used for the 2017 Pilot – the European Commission’s eGovernment Benchmark Report (eGBR). However, further investigation of the data and methodology of the report has led to a change in the metrics used by InCiSE. While the 2017 Pilot took four high-level metrics, the 2019 edition of InCiSE will use 13 more granular metrics.\nThe eGBR uses mystery shopping of eight ‘life events’ to assess the quality of digital public services in all 28 EU member countries and six other neighbouring/partner countries. These life events are designed to capture the majority of interactions that citizens and businesses have with public services in European nations. The services assessed by the eGBR include not only national level services but also those provided by sub-national and local governments. As InCiSE aims to look at the effectiveness of national-level civil services we investigated whether there was a way to exclude non-national services.\nWhile the European Commission publishes the full underlying data for the eGBR, it is not easy to calculate scores based solely on the assessments of national-level services. So, an analysis of the data from the 2016 and 2017 reports was undertaken to look at the pattern of service delivery across the eight life events. The results of this analysis is presented in Table 3.12.C, and shows that for five of the eight life events more than half of the URLs assessed by the eGBR are recorded as ‘national’ level services. However, for the ‘moving house’, ‘owning and driving a car’ and ‘studying’ life events the analysis shows that in most countries the URLs being assessed are sub-national/ local services.\n\n\n\n\nTable 14.2: Proportion of eGBR assessed services identified as ‘national’ level services\n\n\nLife event\nMedian proportion of country assessed URLs that are for 'national' services\nNumber of countries where less than 50% of assessed URLs are for 'national' services (out of 34)\n\n\n\n\nBusiness start-up and early trading\n91%\n3\n\n\nRegular business operations\n83%\n4\n\n\nFamily life\n61%\n13\n\n\nFinding and losing a job\n86%\n4\n\n\nMoving house\n23%\n28\n\n\nOwning and driving a car\n49%\n17\n\n\nSmall claims procedures\n66%\n11\n\n\nStudying\n37%\n25\n\n\n\nTable 3.12.C in the original 2019 publication\n\n\n\n\n\n\n\nFor each of the eight life events the mystery shopping exercise looks across three domains: ‘user centric government’, ‘transparency’ and ‘key enablers’; six of the eight life events are also assessed for the additional domain of ‘cross-border mobility’. As transparency is already covered in InCiSE through the openness indicator, including the eGBR transparency data could be seen as duplicating information already measured elsewhere in the InCiSE framework.\nTherefore, in the 2019 edition of InCiSE rather than use the high-level averages for the four domains (as used in the 2017Pilot), the model uses the ‘user centric’, ‘transparency’ and ‘key enablers’ domain scores for the business start-up, regular business operations, family life, losing and finding a job, and small claims procedure life events. This approach removes scores for the three life events (moving house, owning and driving a car, and studying) where services are typically not delivered by national governments, and reduces potential overlap with the openness indicator by removing scores for the ‘transparency’ domain.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis chapter was presented as section 3.12 in the original 2019 publication.\n\n\n\n\n\n\nLonti, Z. & Woods, M. (2008). Towards Government at a Glance: Identification of Core Data and Issues related to Public Sector Efficiency (OECD Working Papers on Public Governance No. 7). Retrieved from https://doi.org/10.1787/245570167540"
  },
  {
    "objectID": "04_changes.html#sec-changes-methodology",
    "href": "04_changes.html#sec-changes-methodology",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.1 Changes in the overarching methodology",
    "text": "15.1 Changes in the overarching methodology\nThere are two main changes to the overarching methodological approach for the 2019 edition of InCiSE. Firstly, the technical modelling is being done in the R software package, rather than the mix of Excel and Stata that was used for the pilot. This approach reduces the potential for error, while the use of open source software will increase the opportunities for reproducibility. Secondly, a ‘data quality assessment’ has been introduced which makes a quantitative appraisal of the data quality of countries and indicators. This assessment has been used to determine country selection, and to partially account for data quality in the weighting of the indicators into the composite index score."
  },
  {
    "objectID": "04_changes.html#sec-no-change",
    "href": "04_changes.html#sec-no-change",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.2 Indicators with no changes",
    "text": "15.2 Indicators with no changes\nThere are three indicators with no changes to their definition or metrics – policy making, inclusiveness and tax administration. For policy making and tax administration there have been data updates to all metrics, while two of the five metrics in inclusiveness have been updated."
  },
  {
    "objectID": "04_changes.html#sec-minor-changes",
    "href": "04_changes.html#sec-minor-changes",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.3 Indicators with minor changes",
    "text": "15.3 Indicators with minor changes\nThere are five indicators with what we class as ‘minor’ changes, that is changes that we do not believe substantially change or which are not contentious.\nFor the openness, integrity and regulation indicators we have identified some additional metrics in the Bertelsmann Foundation’s Sustainable Governance Indicators that enhance the topic coverage of these indicators.\nFor the integrity indicator we are also making a change to the coding of post-employment cooling-off periods to remove consideration of whether compensation is paid during the cooling-off period due to quality concerns about this aspect of the data.\nFor the fiscal & financial management indicator we are adding three metrics (one from the International Budget Partnership and two from the World Bank) that measure government’s openness/publication of budget and public spending documents and statistics.\nFor the HR management indicator we are incorporating newly published data from the OECD on strategic HRM practices."
  },
  {
    "objectID": "04_changes.html#sec-change-crisis",
    "href": "04_changes.html#sec-change-crisis",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.4 Crisis and risk management",
    "text": "15.4 Crisis and risk management\nThe crisis and risk management indicator has been redesigned, drawing from both the 2017 Pilot source (the Hyogo Framework for Action monitoring reports) and new data from the OECD on the governance of critical risks. The 2017 Pilot data focuses heavily on natural disaster risk management, the OECD data substantially enhances the topic coverage and provide a more rounded view of crisis and risk management practices."
  },
  {
    "objectID": "04_changes.html#sec-change-capabilities",
    "href": "04_changes.html#sec-change-capabilities",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.5 Capabilities",
    "text": "15.5 Capabilities\nA data quality concern about the capabilities indicators is that the data for most countries has a reference date of 2012. It has not been possible to identify new and more up-to-date data for the capabilities indicator (the source data is the OECD Survey of Adult Skills), although further datasets for this data source that expand country coverage for this indicator were identified. This led to a further review of the source data, which led to the identification of a range of additional metrics that could be incorporated into the model. The metrics in the pilot focused on capability levels (literacy, numeracy, problem solving skills, and education level), however the data also includes a number of metrics on the use of skills and learning at work (e.g. use of reading/ writing/ IT skills at work, formal and informal learning for job-related reasons in the past 12 months). Furthermore, the pilot used data for the public sector as a whole, however investigation of the source data suggested that reliable estimates for the ‘public administration’ industrial sector could be produced (this is wider than just the civil service, including things like local government, but excluding things such as healthcare, education and transport). The capabilities indicator has therefore incorporated 10 additional metrics on skills use and learning at work, and switched to using data for the ‘public administration’ industrial sector."
  },
  {
    "objectID": "04_changes.html#sec-change-digital",
    "href": "04_changes.html#sec-change-digital",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.6 Digital services",
    "text": "15.6 Digital services\nThe source data for digital services (the European Commission’s eGovernment Benchmark Report) uses a ‘life events’ model, however for a number of these life events delivery across the countries included in the dataset is at the sub-national/local level. Moreover, one of the domains (transparency) overlaps with an existing InCiSE indicator. Therefore, the way in which data is extracted has been changed to select data for those life events where for a majority of countries the service is delivered at the national level (and therefore likely to be managed by the civil service) and to exclude the transparency domain."
  },
  {
    "objectID": "04_changes.html#sec-change-procurement",
    "href": "04_changes.html#sec-change-procurement",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.7 Procurement",
    "text": "15.7 Procurement\nSince the 2017 Pilot, two data sources have been identified that can provide metrics for an indicator on procurement (an element of the InCiSE framework not covered by the pilot). One source is the OECD’s Survey on Public Procurement which looks at the role of CPBs and strategic approaches to public procurement (e.g. e-procurement and support for SMEs). The other source is the Opentender project, supported by an academic consortium, which analyses the tender and contract notices for procurement exercises using the European Union’s Tenders Electronic Daily service."
  },
  {
    "objectID": "04_changes.html#sec-change-social-security",
    "href": "04_changes.html#sec-change-social-security",
    "title": "15  Summary of changes from the 2017 pilot edition of the InCiSE Index",
    "section": "15.8 Social security administration",
    "text": "15.8 Social security administration\nThe 2017 Pilot included an indicator for social security administration. This was based on a single metric: administrative costs as a proportion of total social protection spending. Feedback received following the publication of the pilot identified significant quality issues with the metric used. No alternative metrics for the indicator were identified, therefore it was decided to depreciate the indicator from the model. Further discussion of this is provided in Chapter 17.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis was chapter 4 in the original 2019 publication."
  },
  {
    "objectID": "05_sensitivity.html#sec-sens-country",
    "href": "05_sensitivity.html#sec-sens-country",
    "title": "16  Sensitivity analysis",
    "section": "16.1 Country selection",
    "text": "16.1 Country selection\nSection 2.3 discusses how the approach to country selection for the 2019 edition of InCiSE differs from the 2017 Pilot, as it now uses the results of the data quality assessment (DQA) to identify countries for inclusion. The DQA produces a score for each country that summarises the quality of the data within the InCiSE model about that country (before imputation of missing values). The threshold for inclusion in the 2019 edition of InCiSE is an overall DQA score of 0.50 or greater.\nThe three countries included in the InCiSE Index with the lowest data quality scores have markedly poorer data quality by indicator than other countries (see Table 2.8.A). For each of these three countries only two or three of the 12 InCiSE indicators are rated green, a further two or three indicators are rated as amber, while five or six are rated as red, and one indicator is fully imputed.\nSection 2.8 also outlines an approach to ‘grading’ countries based on their data quality scores. DQA scores of 0.75 are given an ‘A+’ grade, while those below 0.6 are given a ‘D’ grade. In this ‘D’ group there are four more countries in addition to the three discussed above.\nThe 2017 Pilot used a simpler approach to country inclusion with a threshold of having at least 75% of metrics available, and producing a set of 31 countries1. For the 2019 edition’s set of metrics 31 countries also achieve the 75% threshold but the country coverage differs to the set of countries in the 2017 Pilot.1 One further country in 2017 met this criteria but was not an OECD member so was excluded to simplify interpretation of results.\nThe first two sensitivity tests for country coverage altered the DQA threshold used to determine country inclusion. The first test used a DQA score of 0.55 or higher, excluding the three countries in the 2019 set with the lowest data quality, while the second test used a DQA score of 0.6 or higher. The third test used the 2017 Pilot’s threshold of countries with 75% of data being available. The fourth test used the 31 countries included in the 2017 Pilot."
  },
  {
    "objectID": "05_sensitivity.html#sec-sens-date",
    "href": "05_sensitivity.html#sec-sens-date",
    "title": "16  Sensitivity analysis",
    "section": "16.2 Reference date",
    "text": "16.2 Reference date\nThe reference dates of the source data for the 2019 edition of InCiSE ranges from 2012 to 2018. However, as shown in Table 5.2.A, the reference dates vary across indicators. A third of the metrics have a reference date of 2017 or 2018, around half of the metrics have a reference date of 2015 or 2016, while just 17 out of the 116 metrics have a reference date of 2012.\nOf these 17 metrics, 14 are the metrics for the capabilities indicator. This is the only indicator with 100% of its data with a reference date from before 20152. The capabilities indicator is solely composed of data with a reference year of 2012. Only two other indicators have data from before 2014 but in both cases this is a small number of their constituent metrics.2 The lack of recency of the data source for the capabilities indicator (the OECD’s Survey of Adult Skills) is discussed in Chapter 5.\n\n\n\n\nTable 16.1: Reference year of InCiSE metrics by indicator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndicator\nNumber of metrics per year\nPercent within period...\n\n\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2012-14\n2015-16\n2017-18\n\n\n\n\nCapabilities\n14\n\n\n\n\n\n\n\n\n\n\n\n\n100%\n\n\n\n\n\n\nCrisis and risk management\n\n\n\n\n\n\n8\n5\n\n\n\n\n\n\n100%\n\n\n\n\nDigital services\n\n\n\n\n\n\n\n\n7\n6\n\n\n\n\n54%\n46%\n\n\nFiscal and financial management\n1\n\n\n\n\n\n\n1\n4\n\n\n17%\n17%\n67%\n\n\nHR management\n\n\n\n\n\n\n5\n4\n\n\n\n\n\n\n100%\n\n\n\n\nInclusiveness\n\n\n\n\n\n\n3\n2\n\n\n\n\n\n\n100%\n\n\n\n\nIntegrity\n\n\n1\n2\n11\n\n\n2\n1\n18%\n65%\n18%\n\n\nOpenness\n\n\n\n\n\n\n1\n3\n4\n2\n\n\n40%\n60%\n\n\nPolicy making\n\n\n\n\n\n\n\n\n\n\n\n\n8\n\n\n\n\n100%\n\n\nProcurement\n\n\n\n\n\n\n\n\n6\n\n\n\n\n\n\n100%\n\n\n\n\nRegulation\n\n\n\n\n\n\n\n\n\n\n6\n3\n\n\n\n\n100%\n\n\nTax administration\n\n\n\n\n\n\n5\n\n\n1\n\n\n\n\n83%\n17%\n\n\nTotal\n15\n1\n2\n33\n28\n23\n14\n16%\n53%\n32%\n\n\n\nTable 5.2.A in the original PDF publication\n\n\n\n\n\n\n\nThe first two sensitivity tests for recency exclude the capabilities indicator. In the first analysis the capabilities indicator is excluded but the weightings of the other indicators are not adjusted. In the second analysis the weightings are recalculated to account for the removal of the capabilities indicator.\nIn the third test, only data with a reference year of 2015 or later is included in the model; the four other metrics from before 2014 are excluded in addition to the 14 capabilities metrics. In the fourth test, only data with a reference year of 2016 or later is included in the model; the 51 metrics with a reference date of 2016 or earlier are therefore excluded. For both these analyses there is no adjustment the weightings – either to calculate the indicators from their constituent metrics or to calculate the index from the indicators."
  },
  {
    "objectID": "05_sensitivity.html#sec-sens-weight",
    "href": "05_sensitivity.html#sec-sens-weight",
    "title": "16  Sensitivity analysis",
    "section": "16.3 Alternative approaches to weighting",
    "text": "16.3 Alternative approaches to weighting\nThe InCiSE Index is a weighted aggregation of the InCiSE indicators, which themselves are weighted aggregations of the InCiSE metrics. Section 2.7 set out the approach to weighting the InCiSE indicators to calculate the InCiSE Index. Two-thirds of an indicator’s weight is based on an ‘equal share’ approach (i.e. 1/12), while one-third is based on the results of the data quality assessment. Section 2.6 and Chapters 3-14 outline how the individual metrics are weighted to produce each of the 12 indicator scores.\nThe first three sensitivity tests for alternative weighting look at the proportion of indicator weighting that is assigned to the ‘equal share’ and the data quality assessment. The first test uses a 50:50 split rather than the 67:33 split. The second test uses solely an ‘equal share’ approach (i.e. indicator weights set to 1/12 each). The third test uses solely the results of the data quality assessment to determine the weighting.\nThe fourth and fifth tests focus on metrics weighting: The fourth does not apply weighting to metrics within indicators (i.e. all metrics contribute equally to the calculation of their indicator), and the fifth is a simple summation of the metrics, then normalised as per the standard calculations of the indicators and index (as set out Section 2.5)."
  },
  {
    "objectID": "05_sensitivity.html#sec-sens-base",
    "href": "05_sensitivity.html#sec-sens-base",
    "title": "16  Sensitivity analysis",
    "section": "16.4 Adjusting the base data",
    "text": "16.4 Adjusting the base data\nIn the InCiSE model, metrics are normalised after missing data is imputed. An alternative approach would be to normalise the data before it is imputed.\nThree sensitivity tests were done where normalisation of the data occurred before the imputation. In the first test the data was ranked, in the second test the data was rescaled using the same min-max normalisation applied to the outputs of the model, and in the third test the data was converted to z-scores with a mean of 0 and a standard deviation of 1."
  },
  {
    "objectID": "05_sensitivity.html#sec-sens-impute",
    "href": "05_sensitivity.html#sec-sens-impute",
    "title": "16  Sensitivity analysis",
    "section": "16.5 Alternative imputation methods",
    "text": "16.5 Alternative imputation methods\nAs discussed in section 2.4 missing data in the InCiSE base data is handled through multiple imputation, and in particular the predictive mean matching method.\nFour sensitivity tests were carried out using different approaches to imputation. Section 2.4 outlines how the imputation of missing data is handled on a per-indicator basis, the first test changes this to adopt a “kitchen sink”/“all-in-one” approach in which the full dataset of all 116 metrics (and two external predictor variables) are supplied to the imputation function. The second test uses a modified form of predictive mean matching called ‘midas touch’ to generate imputed values. The third test uses the ‘random forest’ method to generate imputed values, a machine learning approach. The fourth test uses mean imputation, where missing data is replaced with the simple arithmetic mean of the observed data."
  },
  {
    "objectID": "05_sensitivity.html#sec-sens-results",
    "href": "05_sensitivity.html#sec-sens-results",
    "title": "16  Sensitivity analysis",
    "section": "16.6 Results of the sensitivity analysis",
    "text": "16.6 Results of the sensitivity analysis\nTable 16.2 shows the results of the 2019 InCiSE model for each country and the range of ranks across the five different sets of sensitivity analysis, while Figure 16.1 show how the InCiSE Index score varies by country for each of the sensitivity tests carried out. The results of the five sets of sensitivity analysis demonstrate general stability in the model, with country ranks either unchanged or changed by only one or two places on average, and the same groupings of countries at the top and bottom of the rankings. Full results from the sensitivity analysis are provided in Appendix B.\n\n\n\nFigure 16.1: Sensitivity analysis results\n Five line graphs showing the detailed results of the sensitivity analysis. Each graph shows the InCiSE 2019 final index scores for each country compared to the results of each set of tests conducted in the sensitivity analysis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Reference year                                   Alternative imputation method                  Country selection                  Adjusting base data                  Altenative weighting   2019 results Excl CAP Excl CAP & reweight 2015-18 data 2016-18 data 2019 results All-in-one Midas touch Random forests Mean value 2019 results DQA ≥ 0.55 DQA ≥ 0.6 75% of data 2017 countries 2019 results Ranked data Rescaled data Standardised data 2019 results 50:50 Equal weights No internal weights Sum of metrics 0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00   Figures 5.1 to 5.5 in the original 2019 publication.\n\n\n\nIn the country coverage sensitivity analysis, the main driver of change in rankings is due to the exclusion of countries: Figure 5.1 shows that the scores of individual countries do not substantially change as a result of the exclusion of different countries. When varying the reference date there are some changes as a result of the exclusion of the capabilities indicator, and further changes as a result of excluding data with a reference year of 2015 and earlier.\nAltering the weighting schemes for the calculation of the index and indicators does not result in many changes, except when calculating the index as a simple sum of all metrics (i.e. applying no weighting at all). Similarly making alterations to the metrics (e.g. ranking, rescaling, standardisation) before they are imputed does not result in many changes to country scores or rankings.\nVarying the imputation methodology results in slightly more variation of country scores and ranks than the previous sensitivity checks. Only three countries see no change in their ranking, however of those that do change, the difference in ranks is still small at around one or two places.\nOne way to consider the effectiveness of the sensitivity analysis is to calculate the Mean Absolute Error (MAE) arising from the analysis. MAE is a common technique for assessing the quality of statistical models by comparing the difference of the model’s estimates/predictions with the original data. It is calculated as the sum of the absolute errors divided by the number of cases. In the case of the InCiSE sensitivity analysis, ‘error’ is calculated as the difference between the 2019 InCiSE Index results and the results from each of the sensitivity tests.\nThe overall MAE figure for the sensitivity analysis, that is the mean level of ‘error’ across all 20 sensitivity tests for all 38 countries, is ±0.017. The MAE can also be calculated for each sensitivity test or each set of tests. The per-set MAE figures is presented in Table 16.3, while the per-test MAE is presented in the tables in Appendix B. Across the different sets of methodological sensitivity tests, the smallest MAE is ±0.007 for the set of tests varying country selection while the highest MAE is ±0.023 for the set of tests changing the reference date.\nFinally, the MAE can also be calculated by country, which is also included in Table 16.2 and ranges from ±0.001 to ±0.032. However, given that the same two countries place highest and lowest across most tests the minimum per-country MAE is skewed by the limited variability in these two countries’ scores, when excluding these countries the minimum MAE rises from ±0.001 to ±0.009.\n\n\n\n\nTable 16.2: Variation in country ranking across sensitivity analyses\n\n\nCountry\n2019 results\nRange of country's ranks in sensitivity analysis\nMean absolute error (MAE)\n\n\nScore\nRank\nCountry coverage\nReference date\nAlternative weightings\nAdjust base data\nImputation method\n\n\n\n\nGBR\n1.000\n1\n1\n1\n1-2\n1\n1-2\n0.003\n\n\nNZL\n0.980\n2\n2\n2\n1-2\n2\n1-2\n0.019\n\n\nCAN\n0.916\n3\n3\n3\n3\n3\n3-5\n0.021\n\n\nFIN\n0.883\n4\n4\n4-5\n4-5\n4\n3-4\n0.013\n\n\nAUS\n0.863\n5\n5\n4-5\n4-5\n5-6\n4-7\n0.014\n\n\nDNK\n0.832\n6\n5-6\n7-9\n6-8\n5-7\n5-7\n0.021\n\n\nNOR\n0.830\n7\n6-7\n6\n6-7\n6-10\n5-7\n0.010\n\n\nNLD\n0.794\n8\n7-8\n8-9\n8-10\n8-9\n8-9\n0.014\n\n\nKOR\n0.785\n9\n8-10\n9-11\n6-11\n7-11\n10\n0.019\n\n\nSWE\n0.785\n10\n9-10\n7-10\n8-10\n8-9\n8-9\n0.009\n\n\nUSA\n0.765\n11\n11\n10-11\n10-11\n10-11\n11\n0.029\n\n\nEST\n0.674\n12\n10-12\n12-17\n12\n12-13\n12-15\n0.023\n\n\nCHE\n0.650\n13\n11-13\n13-14\n13-14\n12-15\n12-15\n0.020\n\n\nIRL\n0.625\n14\n14-16\n15-16\n14-17\n14-15\n16-17\n0.021\n\n\nFRA\n0.619\n15\n12-15\n12-14\n13-16\n13-15\n12-15\n0.012\n\n\nAUT\n0.617\n16\n13-15\n15-16\n13-16\n16-17\n13-15\n0.014\n\n\nESP\n0.599\n17\n15-17\n13-17\n15-17\n16-17\n16-17\n0.010\n\n\nMEX\n0.507\n18\n17-19\n19-20\n18-24\n18-23\n18-20\n0.020\n\n\nDEU\n0.505\n19\n16-19\n18-21\n18-19\n19-21\n18-20\n0.010\n\n\nLTU\n0.487\n20\n18-20\n18-20\n20-22\n20-21\n20-22\n0.018\n\n\nBEL\n0.485\n21\n19-22\n18-22\n20-21\n19-20\n18-21\n0.017\n\n\nJPN\n0.472\n22\n17-21\n21-22\n19-24\n18-23\n21-24\n0.020\n\n\nLVA\n0.466\n23\n20-23\n23-26\n20-24\n24\n24-26\n0.031\n\n\nCHL\n0.454\n24\n21-24\n23-25\n22-24\n22-23\n21-23\n0.014\n\n\nITA\n0.419\n25\n22-25\n23-25\n25-26\n25\n23-25\n0.014\n\n\nSVN\n0.369\n26\n23-26\n26-28\n25-26\n26\n25-26\n0.018\n\n\nISR\n0.315\n27\n27\n24-27\n27\n27\n27-29\n0.022\n\n\nPOL\n0.282\n28\n24-28\n28-36\n28-29\n28-29\n27-29\n0.025\n\n\nPRT\n0.259\n29\n25-29\n29-30\n28-29\n31\n28-31\n0.015\n\n\nCZE\n0.245\n30\n26-30\n27-32\n30-32\n28-30\n30-31\n0.018\n\n\nISL\n0.228\n31\n31\n30-32\n30-32\n29-30\n28-31\n0.019\n\n\nTUR\n0.189\n32\n27-32\n28-32\n30-35\n32\n32-33\n0.026\n\n\nSVK\n0.172\n33\n28-33\n31-34\n32-35\n33\n32-34\n0.015\n\n\nBGR\n0.147\n34\n—\n34-35\n33-34\n35\n35-36\n0.016\n\n\nHRV\n0.140\n35\n—\n36-37\n34-36\n34\n33-34\n0.019\n\n\nROU\n0.127\n36\n—\n35-37\n36-37\n36\n35-37\n0.022\n\n\nGRC\n0.107\n37\n29-34\n33-35\n34-38\n37\n36-37\n0.027\n\n\nHUN\n0.000\n38\n30-35\n38\n37-38\n38\n38\n0.001\n\n\n\nTable 5.6.A in the original 2019 publication\n\n\n\n\n\n\n\n\n\n\n\nTable 16.3: Summary of variation in ranking changes across sensitivity analysis sets\n\n\n\nCountry coverage\nReference date\nAlternative weightings\nAdjust base data\nImputation method\n\n\n\n\nMean absolute error (MAE)\n0.007\n0.023\n0.018\n0.014\n0.022\n\n\nCountries with no change in rank\n8\n5\n3\n16\n3\n\n\nLargest difference in rank\n5\n8\n6\n5\n3\n\n\nAverage difference in rank\n2\n2\n2\n1\n2\n\n\n\nTable 5.6.A in the original 2019 publication\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis was presented as chapter 5 in the original 2019 publication."
  },
  {
    "objectID": "06_future_development.html#sec-future-ssa",
    "href": "06_future_development.html#sec-future-ssa",
    "title": "17  Future development",
    "section": "17.1 Social security administration",
    "text": "17.1 Social security administration\nThe InCiSE framework (described in Section 1.3) identifies social security administration as one of the constituent functions of an effective central civil service, and the 2017 Pilot edition of the InCiSE Index included an indicator for social security administration. The indicator was based on a single metric, which was the administrative costs of social protection as a proportion of total social protection expenditure. Feedback from the pilot edition included a critique of this metric, saying it was unsuitable given the inclusion of state provided healthcare which varies significantly across countries. Furthermore, the data was available solely for European Union member states, so data for non-EU countries was imputed based on correlated perception measures from the Quality of Governance study used elsewhere in the InCiSE model.\nExploration of the source data did not identify an appropriate method to exclude healthcare costs from the calculations. A review of further data sources identified neither alternative metrics that included non-EU countries nor imputation predictors with a closer intellectual or theoretical relationship to the indicator’s conceptual basis.\nIt was therefore decided that the social security indicator should be removed from the 2019 edition of InCISE. For future editions of the InCiSE Index, we will continue to explore whether there is suitable data to reintroduce a social security indicator."
  },
  {
    "objectID": "06_future_development.html#sec-future-notmeasured",
    "href": "06_future_development.html#sec-future-notmeasured",
    "title": "17  Future development",
    "section": "17.2 Functions and attributes not yet measured",
    "text": "17.2 Functions and attributes not yet measured\nIn addition to social security, four of the functions and attributes identified in the InCiSE framework have not been measured in either edition of the index: IT for officials, internal finance, staff engagement, and innovation. No suitable data has been identified since the pilot that would allow for measurement of these four potential indicators. Future editions of the InCiSE index will continue to explore whether suitable data exists to introduce indicators for these four areas."
  },
  {
    "objectID": "06_future_development.html#sec-future-measured",
    "href": "06_future_development.html#sec-future-measured",
    "title": "17  Future development",
    "section": "17.3 Functions and attributes already measured",
    "text": "17.3 Functions and attributes already measured\nThe 2019 edition of InCiSE has used an additional 46 metrics compared to the 2017 Pilot: six form the new procurement indicator and 40 are distributed across the existing indicators measured in the 2017 Pilot.\nWhile this has strengthened a number of indicators, as Table 2.7 shows only three of the indicators have been given a final ‘RAG’ rating of green (data quality score of 0.75 or more). Table 17.1 below provides some considerations for future improvements of each of the indicators measured in the 2019 edition of InCiSE, with amber or red ‘RAG’ ratings.\n\n\n\n\nTable 17.1: Potential future improvement of indicators measured in the 2019 edition of InCiSE\n\n\nInCiSE indicator\nRAG rating\nPotential routes for future development\n\n\n\n\nIntegrity\n\nAddition to, or replacement of, existing metrics with non-perception based measures.\n\n\nOpenness\n\nn/a\n\n\nCapabilities\n\nIdentification of data sources with more recent data and/or more regular update frequency.\n\n\nInclusiveness\n\nAdditional metrics providing objective measurement of ethnic/religious diversity, and metrics providing objective/subjective measurement of inclusion for other under-represented groups (e.g. disability, age, socio-economic background, LGBT).\n\n\nPolicymaking\n\nAddition of non-perception based measures, including on themes such as timeliness, accuracy, and use of evidence.\n\n\nFiscal & financial management\n\nn/a\n\n\nRegulation\n\nn/a\n\n\nCrisis & risk management\n\nReplacement of the data sourced from the UN’s Hyogo Framework for Action monitoring reports as monitoring data from the Sendai Framework becomes available.\n\n\nHR management\n\nIdentification of data to measure additional themes such as skills gaps/talent deployment, quality of learning and development, and level of satisfaction with HR services.\n\n\nProcurement\n\nAdditional themes such as value for money and the capabilities of procurement officials.\n\n\nTax administration\n\nAdditional themes such as preventing tax evasion.\n\n\nDigital services\n\nIdentification of non-perception based measures, including average transaction time, up-time of systems, proportion of government services available online.\n\n\n\nTable 6.3.A in the original 2019 publication\n\n\n\n\n\n\n\n\n\n\n High data quality\n Medium data quality\n Low data quality"
  },
  {
    "objectID": "06_future_development.html#sec-future-country",
    "href": "06_future_development.html#sec-future-country",
    "title": "17  Future development",
    "section": "17.4 Extending country coverage",
    "text": "17.4 Extending country coverage\nWhile coverage of the InCiSE results has increased from the 31 countries in the 2017 Pilot to 38 in the 2019 edition, the group of countries remains broadly homogeneous, made up of OECD and EU member countries with high or upper-middle incomes. Future editions of the InCiSE Index will continue to use the data quality based approach to country inclusion set out in Section 2.3, however this requires greater data availability for non-OECD/EU countries.\nThere are a number of potential options, such as creating regional versions of the InCiSE Index using existing multi-country data collections for different regions (but for which either OECD or EU countries are not members). Alternatively, subsets of the existing InCiSE Index could be created as some indicators have wider data coverage than others.\nThe InCiSE Partners are committed to identifying ways to increase coverage, and have conducted two short studies of how the InCiSE framework applies in Brazil and Nigeria to inform future thinking.\nWhile extending country coverage will generate a greater set of results, careful consideration will be needed on developing alternative versions of the index and how (if at all) to compare between them.\n\n\n\n\n\n\nCross-referencing note\n\n\n\nThis was presented as chapter 6 in the original 2019 publication."
  },
  {
    "objectID": "99_references.html#sec-data-sources",
    "href": "99_references.html#sec-data-sources",
    "title": "References",
    "section": "Data sources",
    "text": "Data sources\n\n\nBertelsmann Stiftung (2018) Sustainable Governance Indicators 2018, Gütersloh, Germany: Bertelsmann Stiftung, http://www.sgi-network.org\nDahlström C, Teorell J, Dahlberg S, Hartmann F, Lindberg A and Nistotskaya M (2015) The QoG Expert Survey Dataset II, Gothenburg: The Quality of Government Institute, University of Gothenburg, https://qog.pol.gu.se/ data/datadownloads/qogexpertsurveydata\nDIGIWHIST (2018) Opentender, Hungary: Government Transparency Institute, https://opentender.eu\nEuropean Commission (2018) eGovernment Benchmark Report 2018, Brussels: European Commission, https://ec.europa.eu/digital-single-market/en/news/ egovernment-benchmark-2018-digital-efforts-european- countries-are-visibly-paying\nILO (2018) ILO Statistics, Geneva: International Labour Organization, https://www.ilo.org/ilostat/\nInternational Budget Partnership (2018) Open Budget Survey 2017, Washington DC: International Budget Partnership, http://survey.internationalbudget.org\nOECD (2013) Government at a Glance 2013, Paris: Organisation for Economic Cooperation and Development, https://doi.org/10.1787/gov_glance-2013-en\nOECD (2015) Government at a Glance 2015, Paris: Organisation for Economic Cooperation and Development, https://doi.org/10.1787/gov_glance-2015-en\nOECD (2016) Dataset on Public Procurement, Paris: Organisation for Economic Cooperation and Development, https://qdd.oecd.org/subject. aspx?Subject=GOV_PUBPRO_2016\nOECD (2016) Dataset on the Governance of Critical Risks, Paris: Organisation for Economic Cooperation and Development, https://qdd.oecd.org/subject. aspx?Subject=GOV_RISK\nOECD (2017) Government at a Glance 2017, Paris: Organisation for Economic Cooperation and Development, https://doi.org/10.1787/gov_glance-2017-en\nOECD (2017) Tax Administration Comparative Information Series, Paris: Organisation for Economic Cooperation and Development, https://qdd.oecd.org/ subject.aspx?Subject=TAS\nOECD (2018) Composite Indicators of Regulatory Policy and Governance, Paris: Organisation for Economic Cooperation and Development, https://stats.oecd.org/ Index.aspx?QueryId=85336\nOECD (2018) Survey of Adult Skills (Programme for International Assessment of Adult Competencies), Paris: Organisation for Economic Cooperation and Development, http://www.oecd.org/skills/piaac/\nOpen Knowledge International (2017) Global Open Data Index, London: Open Knowledge Foundation, https://index.okfn.org/\nTransparency International (2017) Global Corruption Barometer, Berlin: Transparency International, http://gcb.transparency.org/\nUNDESA (2018) United Nations E-Government Survey 2018, New York: United Nations, https://publicadministration.un.org/egovkb/en-us/Reports/UN-E-Government-Survey-2018\nUNESCO Institute for Statistics (2018) Population by minimum completed level of education (cumulative), Montreal: UNESCO Institute for Statistics, http://data.uis.unesco.org/index.aspx?queryid=168\nUNIDRR (2016) Hyogo Framework for Action National Progress Query Tool, New York: United Nations, https://www.preventionweb.net/applications/hfa/qbnhfa/\nWorld Bank (2017) FMIS And Open Budget Data Global Dataset, Washington DC: The World Bank, https://datacatalog.worldbank.org/dataset/fmis-and-open-budget-data-global-dataset\nWorld Bank (2018) Worldwide Development Indicators, Washington DC: The World Bank, https://data.worldbank.org/indicator/\nWorld Economic Forum (2017) Global Competitiveness Index 2017-18 (Executive Opinion Survey), Geneva: World Economic Forum, http://reports.weforum.org/global-competitiveness-index-2017-2018/downloads/\nWorld Justice Project (2018) Rule of Law Index 2017-18, Washington DC: World Justice Project, https://worldjusticeproject.org/our-work/wjp-rule-law-index/wjp-rule-law-index-2017%E2%80%932018\nWorld Wide Web Foundation (2017) Open Data Barometer: 4th Edition, Washington DC: World Wide Web Foundation, https://opendatabarometer.org/4thedition/"
  },
  {
    "objectID": "99_references.html#sec-software",
    "href": "99_references.html#sec-software",
    "title": "References",
    "section": "Software packages",
    "text": "Software packages\n\n\nArel-Bundock V., Enevoldsen N. and Yetman C. J. (2018) countrycode: An R package to convert country names and country codes, Journal of Open Source Software 3(28): 848, https://doi.org/10.21105/joss.00848\nBache Stefan Milton and Wickham Hadley (2014) magrittr: A Forward-Pipe Operator for R, https://CRAN.R-project.org/package=magrittr\nBescond D. (2021) Rilostat: ILO Open Data via Ilostat Bulk Download Facility or SDMX Web Service, https://CRAN.R-project.org/package=Rilostat\nCaro D. H. and Biecek P. (2017) intsvy: An R Package for Analyzing International Large-Scale Assessment Data, Journal of Statistical Software 81(7), https://doi.org/10.18637/jss.v081.i07\nFirke S. (2018) janitor: Simple Tools for Examining and Cleaning Dirty Data, NA\nMüller K. and Wickham H. (2017) tibble: Simple Data Frames, https://CRAN.R-project.org/package=tibble\nR Core Team (2016) R: A Language and Environment for Statistical Computing, Vienna, Austria: R Foundation for Statistical Computing, https://www.R-project.org/\nvan Buuren S. and Groothuis-Oudshoorn K. (2011) mice: Multivariate Imputation by Chained Equations in R, Journal of Statistical Software 45(3): 1–67, https://doi.org/10.18637/jss.v045.i03\nWickham H. (2016) ggplot2: Elegant Graphics for Data Analysis, New York: Springer-Verlag New York, https://ggplot2.tidyverse.org\nWickham H. (2016) rvest: Easily Harvest (Scrape) Web Pages, https://CRAN.R-project.org/package=rvest\nWickham H. (2017) stringr: Simple, Consistent Wrappers for Common String Operations, https://CRAN.R-project.org/package=stringr\nWickham H. and Bryan J. (2017) readxl: Read Excel Files, https://CRAN.R-project.org/package=readxl\nWickham H. and Henry L. (2017) purrr: Functional Programming Tools, https://CRAN.R-project.org/package=purrr\nWickham H. and Henry L. (2017) tidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions, https://CRAN.R-project.org/package=tidyr\nWickham H. and Miller E. (2017) haven: Import and Export ‘SPSS’, ‘Stata’ and ‘SAS’ Files, https://CRAN.R-project.org/package=haven\nWickham H. and Seidel D. (2017) scales: Scale Functions for Visualization, https://CRAN.R-project.org/package=scales\nWickham H., François R., Henry L. and Müller K. (2017) dplyr: A Grammar of Data Manipulation, https://CRAN.R-project.org/package=dplyr\nWickham H., Hester J. and Bryan J. (2017) readr: Read Rectangular Text Data, https://CRAN.R-project.org/package=readr"
  },
  {
    "objectID": "99_references.html#sec-published-works",
    "href": "99_references.html#sec-published-works",
    "title": "References",
    "section": "Published works and other materials",
    "text": "Published works and other materials\n\n\nArel-Bundock, V., Enevoldsen, N. & Yetman, C.J. (2018). Countrycode:\nAn R package to convert country names and\ncountry codes. Journal of Open Source Software 3(28):\n848. Retrieved from https://doi.org/10.21105/joss.00848\n\n\nBaubion, C. (2013). OECD Risk\nManagement: Strategic Crisis\nManagement (OECD Working Papers on Public Governance\nNo. 23). Retrieved from https://www.oecd-ilibrary.org/governance/oecd-risk-management_5k41rbd1lzr7-en\n\n\nBoviard, T. & Löffler, E. (2003). Public Management\nand Governance. London: Routledge.\n\n\nChristensen, T., Fimreite, A.L. & Lægreid, P. (2011). Crisis\nManagement: The Perceptions of\nCitizens and Civil Servants in\nNorway. Administration & Society\n43(5): 561–594. Retrieved from http://journals.sagepub.com/doi/10.1177/0095399711412914\n\n\nFukuyama, F. (2013). What Is Governance?\nGovernance 26(3): 347–368. Retrieved from https://onlinelibrary.wiley.com/doi/10.1111/gove.12035\n\n\nGoujon, A., K. C., S., Speringer, M., Barakat, B., Potancoková, M.,\nEder, J., … Lutz, W. (2016). A Harmonized\nDataset on Global Educational\nAttainment Between 1970 And 2060\n– An Analytical Window into\nRecent Trends and Future\nProspects in Human Capital\nDevelopment. Journal of Demographic Economics\n82(3): 315–363. Retrieved from https://www.cambridge.org/core/product/identifier/S2054089216000109/type/journal_article\n\n\nGraham, J., Amos, B. & Plumptre, T. (2003). Principles for good\ngovernance in the 21st century (policy brief no. 15). Ottawa:\nInstitute on Governance.\n\n\nGregory, M. & Upson, M. (2017). RAP\nCompanion: Automating the production of\nstatistical reports using DataOps principles. London,\nUK: UK Government Digital Service. Retrieved from https://ukgovdatascience.github.io/rap_companion/\n\n\nHolt, J. & Manning, N. (2014). Fukuyama Is\nRight about Measuring State\nQuality: Now What?\nGovernance 27(4): 717–728. Retrieved from https://onlinelibrary.wiley.com/doi/10.1111/gove.12109\n\n\nInternational Civil Service Commission. (2002). Standards of conduct\nfor the international civil service. New York: United Nations.\nRetrieved from https://icsc.un.org/resources/pdfs/general/standards.pdf\n\n\nInternational Monetary Fund. (2016). Consultation on the\nIMF Guidelines on Governance\nIssues. Retrieved from https://www.imf.org/external/np/exr/consult/2016/governance/\n\n\nKaufman, D., Kraay, A. & Zoido-Lobatón, P. (1999). Governance\nMatters (Policy Research Working Paper No. 2196).\nRetrieved from https://ssrn.com/abstract=188568\n\n\nLonti, Z. & Woods, M. (2008). Towards Government at\na Glance: Identification of Core\nData and Issues related to Public\nSector Efficiency (OECD Working Papers on\nPublic Governance No. 7). Retrieved from https://doi.org/10.1787/245570167540\n\n\nLutz, W., Goujon, A., K. C., S. & Sanderson, W. (2007).\nReconstruction of Populations by Age,\nSex and Level of Educational\nAttainment for 120 Countries for\n1970-2000 (IIASA Interim Report). Laxenburg, Austria: International\nInstitute for Applied Systems Analysis. Retrieved from http://pure.iiasa.ac.at/8453\n\n\nMuriithi, K., Jimenez, M., Jannin, N., Sajid, N., Singh, S. &\nSharma, S. (2015). Quantifying Governance: An\nindicator-based approach. London: LSE/DFID.\n\n\nOECD. (n.d.). Building more effective, accountable, and inclusive\ninstitutions for all. Paris. Retrieved from https://www.oecd.org/dac/post-2015.htm\n\n\nOECD. (2012). Recommendation of the Council on\nRegulatory Policy and Governance\n(explanatory note). Paris: Organisation for Economic Cooperation;\nDevelopment. Retrieved from http://www.oecd.org/gov/regulatory-policy/49990817.pdf\n\n\nOECD. (2015a). Government at a Glance 2015. Paris:\nOrganisation for Economic Cooperation; Development. Retrieved from https://www.oecd-ilibrary.org/governance/government-at-a-glance-2015_gov_glance-2015-en\n\n\nOECD. (2015b). Recommendation of the Council on\nBudgetary Governance (explanatory note).\nParis: Organisation for Economic Cooperation; Development. Retrieved\nfrom http://www.oecd.org/gov/budgeting/Recommendation-\nof-the-Council-on-Budgetary-Governance.pdf\n\n\nOECD, European Union & Joint Research Centre - European Commission.\n(2008). Handbook on Constructing Composite\nIndicators: Methodology and User\nGuide. Organisation for Economic Cooperation;\nDevelopment. Retrieved from https://www.oecd-ilibrary.org/economics/handbook-on-constructing-composite-indicators-methodology-and-user-guide_9789264043466-en\n\n\nOPM & CIPFA. (2004). The Good\nGovernance Standard for Public\nServices. London: The Independent Commission on Good\nGovernance in Public Services.\n\n\nUnited Nations. (1999). Transparency in\nGovernment. Retrieved from http://unpan1.un.org/intradoc/groups/public/documents/un/unpan012062.pdf\n\n\nUNSD. (2018). Statistical Classifications.\nRetrieved from https://unstats.un.org/unsd/class/default.asp\n\n\nvan Buuren, S. (2018). Flexible Imputation of\nMissing Data, Second\nEdition (2nd ed.). Second edition.  Boca\nRaton, Florida : CRC Press, [2019] : Chapman; Hall/CRC.\nRetrieved from https://www.taylorfrancis.com/books/9780429492259\n\n\nvan Buuren, S. & Groothuis-Oudshoorn, K. (2011). Mice:\nMultivariate Imputation by\nChained Equations in R.\nJournal of Statistical Software 45(3): 1–67.\n\n\nWickham, H. & Grolemund, G. (2017). R for data science.\nSebastapol, CA: O’Reilly. Retrieved from https://r4ds.had.co.nz\n\n\nWorld Bank. (2012). Indicators of the Strength of\nPublic Management Systems:\nA key part of the Public Sector\nresults story. Washington DC: The World Bank. Retrieved from http://siteresources.worldbank.org/PUBLICSECTORANDGOVERNANCE/\nResources/285741-1354024300711/ISPMS.pdf\n\n\nWorld Bank. (2016). Benchmarking Public\nProcurement 2017. World Bank, Washington, DC.\nRetrieved from http://hdl.handle.net/10986/32500\n\n\nWorld Bank. (2017). World Development\nReport 2017. Washington DC: The World Bank.\n\n\nWorld Trade Organisation. (2015). Government\nProcurement Agreement: Opening markets and\npromoting good governance. Retrieved from http://wto.org/english/thewto_e/20y_e/gpa_brochure2015_e.pdf"
  },
  {
    "objectID": "A_composite_metrics.html#sec-composite-integrity",
    "href": "A_composite_metrics.html#sec-composite-integrity",
    "title": "Appendix A — Composite metrics",
    "section": "A.1 Integrity",
    "text": "A.1 Integrity\n\n\n\n\nTable A.1: Composite metrics in the integrity indicator\n\n\n\n\n\n\n\n\nInCiSE metric\nSource variables\nCoding\nCalculation\n\n\n\n\nPost-employment cooling-off\n[OECD] Post-public employment cooling-off: other civil servants\nYes = 1; No = 0\nCooling-off period for both = 3; Cooling-off for SCS only = 2; Cooling-off for non-SCS only = 1; No cooling-off for both = 0\n\n\n[OECD] Post-public employment cooling-off: senior civil servants\nYes = 1; No = 0\n\n\nLobbyist protections\n[OECD] Is there an obligation to have a balanced composition of advisory/expert groups?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 3]\n\n\n[OECD] Are lobbyists allowed to sit in advisory/expert groups in a personal capacity?\nYes = 0; No = 1\n\n\n[OECD] Are corporate executives allowed to sit in advisory/ expert groups in a personal capacity?\nYes = 0; No = 1\n\n\nCoverage of whistleblower protections\n[OECD] Scope includes: public sector employees\nYes = 1; No = 0\nSum of variables\n[Range 0 to 6]\n\n\n[OECD] Scope includes: consultants working for the public sector\nYes = 1; No = 0\n\n\n[OECD] Scope includes: suppliers to the public sector\nYes = 1; No = 0\n\n\n[OECD] Scope includes: temporary employees in the public sector\nYes = 1; No = 0\n\n\n[OECD] Scope includes: former public sector employees\nYes = 1; No = 0\n\n\n[OECD] Scope includes: those volunteering for the public sector\nYes = 1; No = 0\n\n\n\nTable A.1 in the original PDF publication\n\n\n\n\n\n\n\nSee Chapter 3 for the full composition of the integrity indicator, Section 3.2 provides more in-depth discussion about the coding of post-employment cooling-off periods."
  },
  {
    "objectID": "A_composite_metrics.html#sec-composite-inclusiveness",
    "href": "A_composite_metrics.html#sec-composite-inclusiveness",
    "title": "Appendix A — Composite metrics",
    "section": "A.2 Inclusiveness",
    "text": "A.2 Inclusiveness\n\n\n\n\nTable A.2: Composite metrics in the inclusiveness indicator\n\n\n\n\n\n\n\n\nInCiSE metric\nSource variables\nCoding\nCalculation\n\n\n\n\nWomen in central government\n[OECD] Women as a proportion of total central government employment\nNo recoding\nAbsolute difference between OECD and ILO variables\n\n\n[ILO] Women as a proportion of the labour market\nNo recoding\n\n\nWomen in the public sector\n[QoG] Women as a proportion of public sector employment\nNo recoding\nAbsolute difference between QoG and ILO variables\n\n\n[ILO] Women as a proportion of the labour market\nNo recoding\n\n\nWomen in top management\n[OECD] Women as a proportion of central government senior management positions\nNo recoding\nAbsolute difference between OECD and ILO variables\n\n\n[ILO] Women as a proportion of the labour market\nNo recoding\n\n\nWomen in senior government\n[QoG] Women as a proportion of senior positions in central government\nNo recoding\nAbsolute difference between QoG and ILO variables\n\n\n[ILO] Women as a proportion of the labour market\nNo recoding\n\n\n\nTable A.2 in the original PDF publication\n\n\n\n\n\n\n\nSee Chapter 6 for the full composition of the inclusiveness indicator."
  },
  {
    "objectID": "A_composite_metrics.html#sec-composite-ffm",
    "href": "A_composite_metrics.html#sec-composite-ffm",
    "title": "Appendix A — Composite metrics",
    "section": "A.3 Fiscal and financial management",
    "text": "A.3 Fiscal and financial management\n\n\n\n\nTable A.3: Composite metrics in the fiscal and financial management indicator\n\n\n\n\n\n\n\n\nInCiSE metric\nSource variables\nCoding\nCalculation\n\n\n\n\nPublished public finance data\n[WB] Consolidated budget execution results for the public sector?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 10]\n\n\n[WB] Sector analysis?\nYes = 1; No = 0\n\n\n[WB] Regional analysis?\nYes = 1; No = 0\n\n\n[WB] Gender analysis?\nYes = 1; No = 0\n\n\n[WB] Budget analysis with special emphasis towards children and youth?\nYes = 1; No = 0\n\n\n[WB] Debt data?\nYes = 1; No = 0\n\n\n[WB] Foreign aid data?\nYes = 1; No = 0\n\n\n[WB] Fiscal data on sub-national/ local governments and municipalities?\nYes = 1; No = 0\n\n\n[WB] Financial statements?\nYes = 1; No = 0\n\n\n[WB] Public procurement and contracts for the whole government?\nYes = 1; No = 0\n\n\n\nTable A.3 in the original PDF publication\n\n\n\n\n\n\n\nSee Chapter 8 for the full composition of the fiscal and financial management indicator."
  },
  {
    "objectID": "A_composite_metrics.html#sec-composite-tax",
    "href": "A_composite_metrics.html#sec-composite-tax",
    "title": "Appendix A — Composite metrics",
    "section": "A.4 Tax administration",
    "text": "A.4 Tax administration\n\n\n\n\nTable A.4: Composite metrics in the tax administration indicator\n\n\n\n\n\n\n\n\nInCiSE metric\nSource variables\nCoding\nCalculation\n\n\n\n\nCollection cost\n[OECD] Total recurrent budget\nNo recoding\nBuget as a proportion of net revenue\n\n\n[OECD] Net revenue\nNo recoding\n\n\nTax debt\n[OECD] Total tax debt\nNo recoding\nTax debt as a proportion of net revenue\n\n\n[OECD] Net revenue\nNo recoding\n\n\nOnline personal tax returns\n[OECD] Personal tax returns filed online\nNo recoding\nOnline returns as a proportion of total returns\n\n\n[OECD] Total personal tax returns filed\nNo recoding\n\n\nOnline corporate tax returns\n[OECD Corporate tax returns filed online\nNo recoding\nOnline returns as a proportion of total returns\n\n\n[OECD] Total corporate tax returns filed\nNo recoding\n\n\nOnline VAT returns\n[OECD] VAT returns filed online\nNo recoding\nOnline returns as a proportion of total returns\n\n\n[OECD] Total VAT returns filed\nNo recoding\n\n\n\nTable A.4 in the original PDF publication\n\n\n\n\n\n\n\nSee Chapter 13 for the full composition of the tax administration indicator."
  },
  {
    "objectID": "A_composite_metrics.html#sec-composite-procurement",
    "href": "A_composite_metrics.html#sec-composite-procurement",
    "title": "Appendix A — Composite metrics",
    "section": "A.5 Procurement",
    "text": "A.5 Procurement\n\n\n\n\nTable A.5: Composite metrics in the procurement indicator\n\n\n\n\n\n\n\n\nInCiSE metric\nSource variables\nCoding\nCalculation\n\n\n\n\nE-procurement functions\n[OECD] Publishing procurement plans\nNational = 1; Partial = 0.5; No = 0\nSum of variables\n[Range 0 to 9]\n\n\n[OECD] Publication of opportunities\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\n[OECD] Announcing tenders\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\n[OECD] Online catalogue\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\n[OECD] Provision of tender documents\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\n[OECD] E-submission of bids\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\n[OECD] E-reverse auctions\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\n[OECD] Notification of award\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\n[OECD] E-submission of invoices\nNational = 1; Partial = 0.5; No = 0; No = 0\n\n\nRole of central purchasing body\n[OECD] CPBs award framework agreements or other consolidated instruments, from which CAs then order\nYes = 1; No = 0\nSum of variables\n[Range 0 to 4\n\n\n[OECD]CPBs act as CAs aggregating demand and purchasing\nYes = 1; No = 0\n\n\n[OECD]CPBs establish policies for CAs\nYes = 1; No = 0\n\n\n[OECD]CPBs co-ordinate training for public officials in charge of public procurement\nYes = 1; No = 0\n\n\nAccess for SMEs\n[OECD] A specific unit specialized in SMEs is in place at the central government level\nYes = 1; No = 0\nSum of variables\n[Range 0 to 5]\n\n\n[OECD] Training and workshops are carried out for SMEs\nYes = 1; No = 0\n\n\n[OECD] Documentation or guidance focused on SMEs is available online\nYes = 1; No = 0\n\n\n[OECD] Division into lots of the contract\nYes = 1; No = 0\n\n\n[OECD] Administrative procedures are simplified for SMEs to participate in tenders\nYes = 1; No = 0\n\n\n\nTable A.5 in the original PDF publication\n\n\n\n\n\n\n\nThe source data for e-procurement functions indicates whether these functions are available in national e-procurement systems and in e-procurement systems for (some) individual entities. Where a country has the functionality in a national system this is coded as 1 (irrespective of whether exists in the systems of individual entities), where there is no functionality indicated in a national system but it is available in some individual entities this is coded as 0.5.\nSee Chapter 11 for the full composition of the procurement indicator."
  },
  {
    "objectID": "A_composite_metrics.html#sec-composite-crm",
    "href": "A_composite_metrics.html#sec-composite-crm",
    "title": "Appendix A — Composite metrics",
    "section": "A.6 Crisis and risk management",
    "text": "A.6 Crisis and risk management\n\n\n\n\nTable A.6: Composite metrics in the crisis and risk management indicator\n\n\n\n\n\n\n\n\nInCiSE metric\nSource variables\nCoding\nCalculation\n\n\n\n\nStrategic approach\n[OECD] Does your government have a national strategy for the management of critical risks?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 7]\n\n\n[OECD] Does your government's national strategy adopt an all-hazards approach to risk?\nYes = 1; No = 0\n\n\n[OECD] Does your government have an institution that is assigned leadership at the national level for the management of critical risks\nYes = 1; No = 0\n\n\n[OECD] Does the lead institution on the management of critical risks report to the centre of government?\nYes = 1; No = 0\n\n\n[OECD] Does the lead institution prepare a report on its functions to the Head of Government and/or a Cabinet level minister?\nYes = 1; No = 0\n\n\n[OECD] Does the institution consult with a variety of stakeholders in the policy-formulation process for the management of critical risks?\nYes = 1; No = 0\n\n\n[OECD] Does your government have a mechanism for monitoring unexpected events in order to quickly build situation awareness about critical riss once they actually occur?\nYes = 1; No = 0\n\n\nLead institution's functions\n[OECD] Lead risk mgmt institution functions: design/ formulate risk management policies\nYes = 1; No = 0\nSum of variables\n[Range 0 to 11]\n\n\n[OECD] Lead risk mgmt institution functions: set priorities and allocate resources accordingly\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: set performance targets\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: provide incentives for policy implementation\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: monitor policy implementation\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: evaluate policy implementation\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: disseminate results of evaluation to the public\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: promote policy coherence across government departments\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: address competing policy objectives\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: coordinate actions across central and local level of government\nYes = 1; No = 0\n\n\n[OECD] Lead risk mgmt institution functions: coordinate cooperation between government and non-governmental entities\nYes = 1; No = 0\n\n\nRisk planning\n[UN] PA1-C1: Is disaster risk taken into account in public investment and planning decisions?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 7]\n\n\n[UN] PA1-C1: National development plan\nYes = 1; No = 0\n\n\n[UN] PA1-C1: Sector strategies and plans\nYes = 1; No = 0\n\n\n[UN] PA1-C1: Climate change policy and strategy\nYes = 1; No = 0\n\n\n[UN] PA1-C1: Poverty reduction strategy papers\nYes = 1; No = 0\n\n\n[UN] PA1-C1: CCA/ UNDAF (Common Country Assessment/ UN Development Assistance Framework)\nYes = 1; No = 0\n\n\n[UN] PA1-C1: Civil defence policy, strategy and contingency planning\nYes = 1; No = 0\n\n\nMulti-hazard assessment\n[UN] PA2-C1: Multi-hazard risk assessment\nYes = 1; No = 0\nSum of variables\n[Range 0 to 8]\n\n\n[UN] PA2-C1: Gender disaggregated vulnerability and capacity assessments\nYes = 1; No = 0\n\n\n[UN] PA2-C1: Agreed national standards for multi hazard risk assessments\nYes = 1; No = 0\n\n\n[UN] PA2-C1: Common format for risk assessment\nYes = 1; No = 0\n\n\n[UN] PA2-C1: Is future/probable risk assessed?\nYes = 1; No = 0\n\n\n[UN] PA5-C4: Damage and loss assessment methodologies and capacities available\nYes = 1; No = 0\n\n\n[UN] PA5-C4: Post-disaster need assessment methodologies\nYes = 1; No = 0\n\n\n[UN] PA5-C4: Post-disaster needs assessment methodologies include guidance on gender aspects\nYes = 1; No = 0\n\n\nRisk monitoring\n[UN] PA2-C2: Are disaster losses and hazards systematically reported, monitored and analyzed?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 4\n\n\n[UN] PA2-C2: Disaster loss databases exist and are regularly updated\nYes = 1; No = 0\n\n\n[UN] PA2-C2: Reports generated and used in planning by finance, planning and sectoral line ministries (from the disaster databases/ information systems)\nYes = 1; No = 0\n\n\n[UN] PA2-C2: Hazards are consistently monitored across localities and territorial boundaries\nYes = 1; No = 0\n\n\nRisk management capability\n[OECD] Does your government undertake efforts to develop risk anticipation capacity\nYes = 1; No = 0\nSum of variables\n[Range 0 to 5]\n\n\n[OECD] Does your government's national strategy for the management of critical risks promote measures to enhance risk prevention and mitigation?\nYes = 1; No = 0\n\n\n[OECD] Does your government have a critical infrastructure protection programme (CIP)?\nYes = 1; No = 0\n\n\n[OECD] Are inter-agency cooperation mechanisms built into your government's crisis management system?\nYes = 1; No = 0\n\n\n[OECD] Does your government encourage the private sector to take steps to ensure business continuity?\nYes = 1; No = 0\n\n\nPreparedness\n[UN] PA5-C1: Are future disaster risks anticipated through scenario development and aligned preparedness planning?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 5]\n\n\n[UN] PA5-C1: Are there national programmes or policies for disaster preparedness, contingency planning and response?\nYes = 1; No = 0\n\n\n[UN] PA5-C1: The institutional mechanisms exist for the rapid mobilisation of resources in a disaster, utilising civil society and the private sector; in addition to public sector support.\nYes = 1; No = 0\n\n\n[UN] PA5-C1: Preparedness plans are regularly updated based on future risk scenarios\nYes = 1; No = 0\n\n\n[UN] PA5-C2: Risk management/contingency plans for continued basic service delivery\nYes = 1; No = 0\n\n\nDisaster spending appraisal\n[UN] PA4-C3: Are the costs and benefits of DRR incorporated into the planning of public investment?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 6]\n\n\n[UN] PA4-C6: Are the impacts of disaster risk that are created by major development projects assessed?\nYes = 1; No = 0\n\n\n[UN] PA4-C6: Are cost/benefits of disaster risk taken into account in the design and operation of major development projects?\nYes = 1; No = 0\n\n\n[UN] PA4-C6: Impacts of disaster risk taken account in Environment Impact Assessment (EIA)\nYes = 1; No = 0\n\n\n[UN] PA4-C6: By national and sub-national authorities and institutions\nYes = 1; No = 0\n\n\n[UN] PA4-C6: By international development actors\nYes = 1; No = 0\n\n\nInternational cooperation\n[UN] PA2-C4: Does your country participate in regional or sub-regional actions to reduce disaster risk?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 6]\n\n\n[UN] PA2-C4: Establishing and maintaining regional hazard monitoring\nYes = 1; No = 0\n\n\n[UN] PA2-C4: Regional or sub-regional risk assessment\nYes = 1; No = 0\n\n\n[UN] PA2-C4: Regional or sub-regional early warning\nYes = 1; No = 0\n\n\n[UN] PA2-C4: Establishing and implementing protocols for transboundary information sharing\nYes = 1; No = 0\n\n\n[UN] PA2-C4: Establishing and resourcing regional and sub-regional strategies and frameworks\nYes = 1; No = 0\n\n\nRisk communications\n[OECD] Does your government encourage a whole-of-society approach to risk communication?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 3]\n\n\n[OECD] Has your government communicated the results of any such evaluations to the public in past?\nYes = 1; No = 0\n\n\n[OECD] Does your government make information that is used for the assessment of critical risks available to the public?\nYes = 1; No = 0\n\n\nEarly warning systems\n[UN] PA2-C3: Do risk prone communities receive timely and understandable warnings of impending hazard events?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 3]\n\n\n[UN] PA2-C3: Communication systems and protocols used and applied\nYes = 1; No = 0\n\n\n[UN] PA2-C3: Active involvement of media in early warning dissemination\nYes = 1; No = 0\n\n\nRisk evaluationa and research\n[OECD] Has your government conducted a post-disaster evaluation of policies that are designed to support the management of critical risks within the last three years?\nYes = 1; No = 0\nSum of variables\n[Range 0 to 3]\n\n\n[OECD] Have the results from such evaluations been used in the design of revised risk management policies?\nYes = 1; No = 0\n\n\n[OECD] Does your government provide support for scientific research that is meant to improve policies for the management of critical risks?\nYes = 1; No = 0\n\n\n\nTable A.6 in the original PDF publication\n\n\n\n\n\n\n\nSee Chapter 10 for the full composition of the crisis and risk management indicator."
  },
  {
    "objectID": "B_sensitivity_detailed.html",
    "href": "B_sensitivity_detailed.html",
    "title": "Appendix B — Sensitivity analysis – detailed results",
    "section": "",
    "text": "This Annex provides detailed results from the sensitivity analysis described in Chapter 16. Each table includes the index score and rank for each of the 38 countries included in the 2019 InCiSE Index results for each of the sensitivity tests carried out alongside the results of the 2019 index results.\nTable B.1 shows the results of the sensitivity tests varying country coverage (Section 16.1):\n\nUsing a data quality assessment threshold of 0.55 to determine country inclusion;\nUsing a data quality assessment threshold of 0.6 to determine country inclusion;\nUsing a threshold of 75% of the available data to determine country inclusion;\nUsing only the countries included in the 2017 Pilot edition of the index.\n\nTable B.2 shows the results of the sensitivity tests varying the reference date (Section 16.2):\n\nExcluding the capabilities indicator;\nExcluding the capabilities indicator and adjusting the weighting accordingly;\nUsing only data with a reference year of 2015 or later;\nUsing only data with a reference year of 2016 or later.\n\nTable B.3 shows the results of the sensitivity tests using alternative weighting (Section 16.3):\n\nUsing a 50:50 split for the equal-share and data-quality based weighting;\nUsing only equal indicator weights(i.e. all indicator weights equal 1/12);\nUsing only indicator weights based on the data quality assessment results;\nNot applying any within-indicator weights;\nCalculating the index as a sum of all metrics.\n\nTable B.4 shows the results of the sensitivity tests adjusting the base data (Section 16.4):\n\nRanking the metrics before imputation;\nRescaling the metrics before imputation;\nStandardising the metrics before imputation.\n\nTable B.5 shows the results of the sensitivity tests using alternative imputation methods (Section 16.5):\n\nUsing an ‘all-in-one’ approach for imputation of missing data;\nUsing the ‘midas touch’ method for imputation of missing data;\nUsing the ‘random forests’ method for imputation of missing data;\nReplacing missing data with the mean of observed values.\n\n\n\n\n\nTable B.1: Sensitivity tests varying country coverage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nIndex score\nCountry rank\n\n\n2019 results\nDQA ≥ 0.55\nDQA ≥ 0.6\n75% of data\n2017 group\n2019 results\nDQA ≥ 0.55\nDQA ≥ 0.6\n75% of data\n2017 group\n\n\n\n\n========\n===========\n=======\n=======\n=======\n=========\n=========\n=======\n=======\n=======\n=========\n\n\nGBR\n1.000\n1.000\n1.000\n1.000\n1.000\n1\n1\n1\n1\n1\n\n\nNZL\n0.980\n0.987\n0.987\n0.992\n0.985\n2\n2\n2\n2\n2\n\n\nCAN\n0.916\n0.907\n0.902\n0.906\n0.898\n3\n3\n3\n3\n3\n\n\nFIN\n0.883\n0.887\n0.881\n0.886\n0.879\n4\n4\n4\n4\n4\n\n\nAUS\n0.863\n0.859\n0.858\n\n\n0.859\n5\n5\n5\n\n\n5\n\n\nDNK\n0.832\n0.854\n0.847\n0.850\n0.843\n6\n6\n6\n5\n6\n\n\nNOR\n0.830\n0.832\n0.830\n0.831\n0.828\n7\n7\n7\n6\n7\n\n\nNLD\n0.794\n0.792\n0.790\n0.790\n0.786\n8\n8\n8\n7\n8\n\n\nKOR\n0.785\n0.781\n0.779\n0.777\n0.773\n9\n9\n9\n8\n10\n\n\nSWE\n0.785\n0.773\n0.775\n0.775\n0.775\n10\n10\n10\n9\n9\n\n\nUSA\n0.765\n0.759\n\n\n\n\n0.758\n11\n11\n\n\n\n\n11\n\n\nEST\n0.674\n0.675\n0.674\n0.672\n0.671\n12\n12\n11\n10\n12\n\n\nCHE\n0.650\n0.639\n0.635\n0.641\n0.635\n13\n13\n12\n11\n13\n\n\nIRL\n0.625\n0.623\n0.617\n0.619\n0.611\n14\n16\n15\n14\n16\n\n\nFRA\n0.619\n0.626\n0.627\n0.627\n0.628\n15\n15\n13\n12\n14\n\n\nAUT\n0.617\n0.626\n0.621\n0.624\n0.620\n16\n14\n14\n13\n15\n\n\nESP\n0.599\n0.596\n0.589\n0.586\n0.590\n17\n17\n16\n15\n17\n\n\nMEX\n0.507\n0.500\n0.504\n\n\n0.505\n18\n19\n17\n\n\n18\n\n\nDEU\n0.505\n0.502\n0.503\n0.504\n0.502\n19\n18\n18\n16\n19\n\n\nLTU\n0.487\n0.490\n0.483\n0.484\n\n\n20\n20\n19\n18\n\n\n\n\nBEL\n0.485\n0.483\n0.475\n0.482\n0.473\n21\n22\n21\n19\n21\n\n\nJPN\n0.472\n0.485\n0.481\n0.488\n0.479\n22\n21\n20\n17\n20\n\n\nLVA\n0.466\n0.471\n0.463\n0.462\n\n\n23\n23\n22\n20\n\n\n\n\nCHL\n0.454\n0.451\n0.450\n0.452\n0.446\n24\n24\n23\n21\n22\n\n\nITA\n0.419\n0.431\n0.428\n0.424\n0.427\n25\n25\n24\n22\n23\n\n\nSVN\n0.369\n0.359\n0.358\n0.360\n0.359\n26\n26\n25\n23\n24\n\n\nISR\n0.315\n0.322\n\n\n\n\n\n\n27\n27\n\n\n\n\n\n\n\n\nPOL\n0.282\n0.277\n0.274\n0.281\n0.274\n28\n28\n26\n24\n25\n\n\nPRT\n0.259\n0.260\n0.260\n0.259\n0.258\n29\n29\n27\n25\n27\n\n\nCZE\n0.245\n0.260\n0.260\n0.257\n0.259\n30\n30\n28\n26\n26\n\n\nISL\n0.228\n0.233\n\n\n\n\n\n\n31\n31\n\n\n\n\n\n\n\n\nTUR\n0.189\n0.181\n0.184\n0.176\n0.182\n32\n32\n29\n27\n28\n\n\nSVK\n0.172\n0.178\n0.175\n0.171\n0.175\n33\n33\n30\n28\n29\n\n\nBGR\n0.147\n\n\n\n\n\n\n\n\n34\n\n\n\n\n\n\n\n\n\n\nHRV\n0.140\n\n\n\n\n\n\n\n\n35\n\n\n\n\n\n\n\n\n\n\nROU\n0.127\n\n\n\n\n\n\n\n\n36\n\n\n\n\n\n\n\n\n\n\nGRC\n0.107\n0.103\n0.098\n0.092\n0.098\n37\n34\n31\n29\n30\n\n\nHUN\n0.000\n0.000\n0.000\n0.000\n0.000\n38\n35\n32\n30\n31\n\n\nMAE\n—\n0.006\n0.006\n0.007\n0.007\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable B.1 in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n\nTable B.2: Sensitivity tests varying reference year\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nIndex score\nCountry rank\n\n\n2019 results\nExcl. CAP\nExcl. CAP & reweight\n2015-2018 data\n2016-2018 data\n2019 results\nExcl. CAP\nExcl. CAP & reweight\n2015-2018 data\n2016-2018 data\n\n\n\n\n========\n===========\n=========\n=========\n=========\n=========\n=========\n=========\n=========\n=========\n=========\n\n\nGBR\n1.000\n1.000\n1.000\n1.000\n1.000\n1\n1\n1\n1\n1\n\n\nNZL\n0.980\n0.955\n0.955\n0.949\n0.912\n2\n2\n2\n2\n2\n\n\nCAN\n0.916\n0.906\n0.906\n0.895\n0.834\n3\n3\n3\n3\n3\n\n\nFIN\n0.883\n0.873\n0.873\n0.881\n0.830\n4\n5\n5\n4\n4\n\n\nAUS\n0.863\n0.875\n0.875\n0.869\n0.810\n5\n4\n4\n5\n5\n\n\nDNK\n0.832\n0.817\n0.817\n0.789\n0.775\n6\n7\n7\n9\n8\n\n\nNOR\n0.830\n0.836\n0.836\n0.843\n0.791\n7\n6\n6\n6\n6\n\n\nNLD\n0.794\n0.802\n0.802\n0.790\n0.758\n8\n8\n8\n8\n9\n\n\nKOR\n0.785\n0.799\n0.799\n0.784\n0.711\n9\n9\n9\n10\n11\n\n\nSWE\n0.785\n0.791\n0.791\n0.802\n0.787\n10\n10\n10\n7\n7\n\n\nUSA\n0.765\n0.740\n0.741\n0.735\n0.731\n11\n11\n11\n11\n10\n\n\nEST\n0.674\n0.664\n0.665\n0.639\n0.594\n12\n12\n12\n12\n17\n\n\nCHE\n0.650\n0.653\n0.653\n0.639\n0.597\n13\n14\n14\n13\n14\n\n\nIRL\n0.625\n0.622\n0.623\n0.619\n0.594\n14\n16\n16\n15\n15\n\n\nFRA\n0.619\n0.655\n0.656\n0.628\n0.636\n15\n13\n13\n14\n12\n\n\nAUT\n0.617\n0.635\n0.636\n0.606\n0.594\n16\n15\n15\n16\n16\n\n\nESP\n0.599\n0.608\n0.609\n0.593\n0.602\n17\n17\n17\n17\n13\n\n\nMEX\n0.507\n0.519\n0.519\n0.519\n0.523\n18\n20\n20\n19\n19\n\n\nDEU\n0.505\n0.521\n0.521\n0.506\n0.536\n19\n19\n19\n21\n18\n\n\nLTU\n0.487\n0.534\n0.534\n0.518\n0.484\n20\n18\n18\n20\n20\n\n\nBEL\n0.485\n0.506\n0.506\n0.526\n0.434\n21\n21\n21\n18\n22\n\n\nJPN\n0.472\n0.495\n0.495\n0.482\n0.444\n22\n22\n22\n22\n21\n\n\nLVA\n0.466\n0.474\n0.474\n0.454\n0.349\n23\n23\n23\n24\n26\n\n\nCHL\n0.454\n0.463\n0.463\n0.473\n0.396\n24\n24\n24\n23\n25\n\n\nITA\n0.419\n0.451\n0.452\n0.442\n0.427\n25\n25\n25\n25\n23\n\n\nSVN\n0.369\n0.363\n0.363\n0.351\n0.271\n26\n26\n26\n26\n28\n\n\nISR\n0.315\n0.332\n0.333\n0.326\n0.401\n27\n27\n27\n27\n24\n\n\nPOL\n0.282\n0.268\n0.269\n0.237\n0.083\n28\n28\n28\n30\n36\n\n\nPRT\n0.259\n0.256\n0.256\n0.238\n0.220\n29\n30\n30\n29\n29\n\n\nCZE\n0.245\n0.240\n0.240\n0.221\n0.309\n30\n31\n31\n32\n27\n\n\nISL\n0.228\n0.238\n0.238\n0.233\n0.218\n31\n32\n32\n31\n30\n\n\nTUR\n0.189\n0.261\n0.262\n0.244\n0.141\n32\n29\n29\n28\n32\n\n\nSVK\n0.172\n0.156\n0.156\n0.159\n0.150\n33\n34\n34\n33\n31\n\n\nBGR\n0.147\n0.153\n0.153\n0.135\n0.110\n34\n35\n35\n34\n34\n\n\nHRV\n0.140\n0.144\n0.144\n0.118\n0.073\n35\n36\n36\n36\n37\n\n\nROU\n0.127\n0.128\n0.128\n0.105\n0.104\n36\n37\n37\n37\n35\n\n\nGRC\n0.107\n0.158\n0.158\n0.129\n0.113\n37\n33\n33\n35\n33\n\n\nHUN\n0.000\n0.000\n0.000\n0.000\n0.000\n38\n38\n38\n38\n38\n\n\nMAE\n—\n0.015\n0.015\n0.017\n0.045\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable B.2 in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n\nTable B.3: Sensitivity tests with alternative approaches to weighting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nIndex score\nCountry rank\n\n\n2019 results\n50:50\nEqual weights\nAll DQA weights\nNo within indicator\nSum of metrics\n2019 results\n50:50\nEqual weights\nAll DQA weights\nNo within indicator\nSum of metrics\n\n\n\n\n========\n===========\n=========\n==========\n========\n=============\n========\n=========\n=========\n==========\n========\n=============\n========\n\n\nGBR\n1.000\n1.000\n0.999\n1.000\n1.000\n0.949\n1\n1\n2\n1\n1\n2\n\n\nNZL\n0.980\n0.970\n1.000\n0.941\n0.941\n1.000\n2\n2\n1\n2\n2\n1\n\n\nCAN\n0.916\n0.911\n0.927\n0.895\n0.896\n0.928\n3\n3\n3\n3\n3\n3\n\n\nFIN\n0.883\n0.876\n0.895\n0.858\n0.824\n0.897\n4\n4\n4\n4\n5\n4\n\n\nAUS\n0.863\n0.859\n0.869\n0.850\n0.864\n0.864\n5\n5\n5\n5\n4\n5\n\n\nDNK\n0.832\n0.823\n0.851\n0.797\n0.774\n0.855\n6\n7\n6\n7\n8\n6\n\n\nNOR\n0.830\n0.825\n0.839\n0.812\n0.805\n0.851\n7\n6\n7\n6\n7\n7\n\n\nNLD\n0.794\n0.787\n0.809\n0.765\n0.745\n0.783\n8\n8\n8\n10\n10\n10\n\n\nKOR\n0.785\n0.786\n0.784\n0.786\n0.809\n0.787\n9\n9\n11\n8\n6\n9\n\n\nSWE\n0.785\n0.782\n0.790\n0.775\n0.763\n0.805\n10\n10\n9\n9\n9\n8\n\n\nUSA\n0.765\n0.754\n0.787\n0.722\n0.724\n0.781\n11\n11\n10\n11\n11\n11\n\n\nEST\n0.674\n0.667\n0.687\n0.649\n0.657\n0.740\n12\n12\n12\n12\n12\n12\n\n\nCHE\n0.650\n0.647\n0.656\n0.637\n0.613\n0.639\n13\n13\n13\n13\n14\n14\n\n\nIRL\n0.625\n0.616\n0.641\n0.593\n0.598\n0.601\n14\n15\n14\n15\n16\n17\n\n\nFRA\n0.619\n0.618\n0.620\n0.615\n0.635\n0.609\n15\n14\n16\n14\n13\n16\n\n\nAUT\n0.617\n0.608\n0.635\n0.583\n0.607\n0.649\n16\n16\n15\n16\n15\n13\n\n\nESP\n0.599\n0.593\n0.611\n0.576\n0.589\n0.611\n17\n17\n17\n17\n17\n15\n\n\nMEX\n0.507\n0.511\n0.497\n0.524\n0.497\n0.412\n18\n18\n19\n18\n19\n24\n\n\nDEU\n0.505\n0.503\n0.507\n0.499\n0.514\n0.525\n19\n19\n18\n19\n18\n18\n\n\nLTU\n0.487\n0.489\n0.483\n0.494\n0.482\n0.470\n20\n20\n21\n20\n20\n22\n\n\nBEL\n0.485\n0.482\n0.491\n0.473\n0.477\n0.488\n21\n21\n20\n21\n21\n21\n\n\nJPN\n0.472\n0.471\n0.475\n0.467\n0.438\n0.503\n22\n22\n23\n22\n24\n19\n\n\nLVA\n0.466\n0.460\n0.479\n0.442\n0.447\n0.498\n23\n23\n22\n24\n23\n20\n\n\nCHL\n0.454\n0.451\n0.459\n0.444\n0.461\n0.440\n24\n24\n24\n23\n22\n23\n\n\nITA\n0.419\n0.419\n0.418\n0.420\n0.436\n0.368\n25\n25\n25\n25\n25\n26\n\n\nSVN\n0.369\n0.360\n0.388\n0.333\n0.338\n0.394\n26\n26\n26\n26\n26\n25\n\n\nISR\n0.315\n0.309\n0.326\n0.294\n0.314\n0.334\n27\n27\n27\n27\n27\n27\n\n\nPOL\n0.282\n0.276\n0.293\n0.261\n0.236\n0.291\n28\n28\n28\n28\n29\n28\n\n\nPRT\n0.259\n0.253\n0.273\n0.235\n0.241\n0.289\n29\n29\n29\n29\n28\n29\n\n\nCZE\n0.245\n0.240\n0.253\n0.228\n0.174\n0.254\n30\n30\n30\n30\n32\n31\n\n\nISL\n0.228\n0.223\n0.239\n0.207\n0.218\n0.270\n31\n31\n31\n32\n31\n30\n\n\nTUR\n0.189\n0.194\n0.177\n0.209\n0.231\n0.063\n32\n32\n32\n31\n30\n35\n\n\nSVK\n0.172\n0.170\n0.175\n0.166\n0.107\n0.143\n33\n33\n33\n33\n35\n32\n\n\nBGR\n0.147\n0.146\n0.150\n0.141\n0.129\n0.127\n34\n34\n34\n34\n33\n33\n\n\nHRV\n0.140\n0.140\n0.140\n0.140\n0.086\n0.069\n35\n35\n35\n35\n36\n34\n\n\nROU\n0.127\n0.131\n0.120\n0.140\n0.070\n0.050\n36\n36\n36\n36\n37\n36\n\n\nGRC\n0.107\n0.111\n0.099\n0.123\n0.123\n0.000\n37\n37\n37\n37\n34\n38\n\n\nHUN\n0.000\n0.000\n0.000\n0.000\n0.000\n0.023\n38\n38\n38\n38\n38\n37\n\n\nMAE\n—\n0.004\n0.009\n0.017\n0.026\n0.032\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable B.3 in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n\nTable B.4: Sensitivity tests adjusting the base data\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nIndex score\nCountry rank\n\n\n2019 results\nRanked data\nRescaled data\nStandardise data\n2019 results\nRanked data\nRescaled data\nStandardise data\n\n\n\n\n========\n===========\n=========\n============\n========\n=========\n=========\n============\n========\n\n\nGBR\n1.000\n1.000\n1.000\n1.000\n1\n1\n1\n1\n\n\nNZL\n0.980\n0.951\n0.978\n0.979\n2\n2\n2\n2\n\n\nCAN\n0.916\n0.893\n0.927\n0.908\n3\n3\n3\n3\n\n\nFIN\n0.883\n0.883\n0.885\n0.885\n4\n4\n4\n4\n\n\nAUS\n0.863\n0.833\n0.868\n0.864\n5\n6\n5\n5\n\n\nDNK\n0.832\n0.862\n0.824\n0.827\n6\n5\n7\n7\n\n\nNOR\n0.830\n0.789\n0.830\n0.829\n7\n10\n6\n6\n\n\nNLD\n0.794\n0.815\n0.794\n0.783\n8\n8\n8\n9\n\n\nKOR\n0.785\n0.818\n0.767\n0.770\n9\n7\n10\n11\n\n\nSWE\n0.785\n0.802\n0.785\n0.784\n10\n9\n9\n8\n\n\nUSA\n0.765\n0.775\n0.737\n0.781\n11\n11\n11\n10\n\n\nEST\n0.674\n0.680\n0.666\n0.671\n12\n13\n12\n12\n\n\nCHE\n0.650\n0.681\n0.630\n0.625\n13\n12\n15\n13\n\n\nIRL\n0.625\n0.588\n0.631\n0.623\n14\n15\n14\n14\n\n\nFRA\n0.619\n0.632\n0.633\n0.620\n15\n14\n13\n15\n\n\nAUT\n0.617\n0.573\n0.622\n0.612\n16\n17\n16\n16\n\n\nESP\n0.599\n0.577\n0.598\n0.591\n17\n16\n17\n17\n\n\nMEX\n0.507\n0.461\n0.517\n0.522\n18\n23\n18\n18\n\n\nDEU\n0.505\n0.506\n0.497\n0.488\n19\n20\n19\n21\n\n\nLTU\n0.487\n0.495\n0.490\n0.497\n20\n21\n21\n20\n\n\nBEL\n0.485\n0.514\n0.493\n0.513\n21\n19\n20\n19\n\n\nJPN\n0.472\n0.521\n0.478\n0.484\n22\n18\n23\n22\n\n\nLVA\n0.466\n0.432\n0.461\n0.453\n23\n24\n24\n24\n\n\nCHL\n0.454\n0.465\n0.484\n0.474\n24\n22\n22\n23\n\n\nITA\n0.419\n0.402\n0.415\n0.412\n25\n25\n25\n25\n\n\nSVN\n0.369\n0.386\n0.366\n0.361\n26\n26\n26\n26\n\n\nISR\n0.315\n0.322\n0.324\n0.327\n27\n27\n27\n27\n\n\nPOL\n0.282\n0.242\n0.276\n0.273\n28\n29\n28\n28\n\n\nPRT\n0.259\n0.223\n0.252\n0.238\n29\n31\n31\n31\n\n\nCZE\n0.245\n0.275\n0.257\n0.251\n30\n28\n29\n30\n\n\nISL\n0.228\n0.230\n0.254\n0.263\n31\n30\n30\n29\n\n\nTUR\n0.189\n0.185\n0.179\n0.190\n32\n32\n32\n32\n\n\nSVK\n0.172\n0.170\n0.177\n0.162\n33\n33\n33\n33\n\n\nBGR\n0.147\n0.122\n0.135\n0.113\n34\n35\n35\n35\n\n\nHRV\n0.140\n0.131\n0.151\n0.139\n35\n34\n34\n34\n\n\nROU\n0.127\n0.107\n0.102\n0.090\n36\n36\n36\n36\n\n\nGRC\n0.107\n0.072\n0.066\n0.075\n37\n37\n37\n37\n\n\nHUN\n0.000\n0.000\n0.000\n0.000\n38\n38\n38\n38\n\n\nMAE\n—\n0.021\n0.010\n0.011\n\n\n\n\n\n\n\n\n\n\n\nTable B.4 in the original PDF publication\n\n\n\n\n\n\n\n\n\n\n\nTable B.5: Sensitivity tests adjusting the base data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nIndex score\nCountry rank\n\n\n2019 results\nAll-in-one\nMidas touch\nRandom forests\nMean value\n2019 results\nAll-in-one\nMidas touch\nRandom forests\nMean value\n\n\n\n\n========\n===========\n==========\n==========\n=======\n=========\n=========\n==========\n==========\n=======\n=========\n\n\nGBR\n1.000\n0.989\n1.000\n1.000\n1.000\n1\n2\n1\n1\n1\n\n\nNZL\n0.980\n1.000\n0.975\n0.981\n0.966\n2\n1\n2\n2\n2\n\n\nCAN\n0.916\n0.862\n0.902\n0.891\n0.867\n3\n5\n3\n3\n3\n\n\nFIN\n0.883\n0.881\n0.884\n0.874\n0.850\n4\n3\n4\n4\n4\n\n\nAUS\n0.863\n0.872\n0.807\n0.854\n0.821\n5\n4\n7\n5\n6\n\n\nDNK\n0.832\n0.833\n0.838\n0.837\n0.808\n6\n7\n5\n6\n7\n\n\nNOR\n0.830\n0.834\n0.831\n0.831\n0.824\n7\n6\n6\n7\n5\n\n\nNLD\n0.794\n0.791\n0.794\n0.766\n0.762\n8\n9\n8\n9\n9\n\n\nKOR\n0.785\n0.738\n0.764\n0.755\n0.728\n9\n10\n10\n10\n10\n\n\nSWE\n0.785\n0.799\n0.792\n0.785\n0.788\n10\n8\n9\n8\n8\n\n\nUSA\n0.765\n0.691\n0.747\n0.721\n0.699\n11\n11\n11\n11\n11\n\n\nEST\n0.674\n0.639\n0.627\n0.665\n0.590\n12\n12\n13\n12\n15\n\n\nCHE\n0.650\n0.621\n0.646\n0.613\n0.595\n13\n15\n12\n14\n13\n\n\nIRL\n0.625\n0.562\n0.608\n0.601\n0.534\n14\n17\n16\n16\n17\n\n\nFRA\n0.619\n0.629\n0.619\n0.603\n0.605\n15\n13\n14\n15\n12\n\n\nAUT\n0.617\n0.621\n0.618\n0.614\n0.593\n16\n14\n15\n13\n14\n\n\nESP\n0.599\n0.609\n0.598\n0.598\n0.574\n17\n16\n17\n17\n16\n\n\nMEX\n0.507\n0.460\n0.498\n0.485\n0.482\n18\n20\n18\n19\n19\n\n\nDEU\n0.505\n0.488\n0.494\n0.484\n0.490\n19\n18\n19\n20\n18\n\n\nLTU\n0.487\n0.431\n0.472\n0.474\n0.427\n20\n22\n20\n21\n22\n\n\nBEL\n0.485\n0.465\n0.471\n0.501\n0.447\n21\n19\n21\n18\n20\n\n\nJPN\n0.472\n0.421\n0.460\n0.452\n0.429\n22\n24\n22\n23\n21\n\n\nLVA\n0.466\n0.367\n0.414\n0.423\n0.365\n23\n26\n24\n24\n25\n\n\nCHL\n0.454\n0.447\n0.458\n0.469\n0.419\n24\n21\n23\n22\n23\n\n\nITA\n0.419\n0.426\n0.412\n0.405\n0.397\n25\n23\n25\n25\n24\n\n\nSVN\n0.369\n0.395\n0.368\n0.363\n0.358\n26\n25\n26\n26\n26\n\n\nISR\n0.315\n0.246\n0.294\n0.322\n0.269\n27\n29\n27\n27\n27\n\n\nPOL\n0.282\n0.302\n0.277\n0.262\n0.260\n28\n27\n28\n29\n28\n\n\nPRT\n0.259\n0.294\n0.266\n0.241\n0.252\n29\n28\n29\n31\n30\n\n\nCZE\n0.245\n0.219\n0.227\n0.241\n0.243\n30\n30\n31\n30\n31\n\n\nISL\n0.228\n0.207\n0.235\n0.297\n0.254\n31\n31\n30\n28\n29\n\n\nTUR\n0.189\n0.184\n0.195\n0.197\n0.180\n32\n33\n32\n32\n32\n\n\nSVK\n0.172\n0.203\n0.170\n0.153\n0.132\n33\n32\n33\n33\n34\n\n\nBGR\n0.147\n0.138\n0.144\n0.095\n0.129\n34\n35\n35\n36\n35\n\n\nHRV\n0.140\n0.144\n0.159\n0.145\n0.169\n35\n34\n34\n34\n33\n\n\nROU\n0.127\n0.095\n0.128\n0.101\n0.121\n36\n37\n36\n35\n36\n\n\nGRC\n0.107\n0.119\n0.081\n0.075\n0.066\n37\n36\n37\n37\n37\n\n\nHUN\n0.000\n0.000\n0.000\n0.000\n0.000\n38\n38\n38\n38\n38\n\n\nMAE\n—\n0.026\n0.011\n0.018\n0.032\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable B.5 in the original PDF publication"
  }
]